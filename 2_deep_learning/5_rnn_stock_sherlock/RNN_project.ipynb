{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Recurrent Neural Network Projects\n",
    "\n",
    "Welcome to the Recurrent Neural Network Project in the Artificial Intelligence Nanodegree! In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.  \n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation TODOs in this notebook\n",
    "\n",
    "This notebook contains two problems, cut into a variety of TODOs.  Make sure to complete each section containing a TODO marker throughout the notebook.  For convenience we provide links to each of these sections below.\n",
    "\n",
    "[TODO #1: Implement a function to window time series](#TODO_1)\n",
    "\n",
    "[TODO #2: Create a simple RNN model using keras to perform regression](#TODO_2)\n",
    "\n",
    "[TODO #3: Finish cleaning a large text corpus](#TODO_3)\n",
    "\n",
    "[TODO #4: Implement a function to window a large text corpus](#TODO_4)\n",
    "\n",
    "[TODO #5: Create a simple RNN model using keras to perform multiclass classification](#TODO_5)\n",
    "\n",
    "[TODO #6: Generate text using a fully trained RNN model and a variety of input sequences](#TODO_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Perform time series prediction \n",
    "\n",
    "In this project you will perform time series prediction using a Recurrent Neural Network regressor.  In particular you will re-create the figure shown in the notes - where the stock price of Apple was forecasted (or predicted) 7 days in advance.  In completing this exercise you will learn how to construct RNNs using Keras, which will also aid in completing the second project in this notebook.\n",
    "\n",
    "The particular network architecture we will employ for our RNN is known as  [Long Term Short Memory (LTSM)](https://en.wikipedia.org/wiki/Long_short-term_memory), which helps significantly avoid technical problems with optimization of RNNs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Getting started\n",
    "\n",
    "First we must load in our time series - a history of around 140 days of Apple's stock price.  Then we need to perform a number of pre-processing steps to prepare it for use with an RNN model.  First off, it is good practice to normalize time series - by normalizing its range.  This helps us avoid serious numerical issues associated how common activation functions (like tanh) transform very large (positive or negative) numbers, as well as helping us to avoid related issues when computing derivatives.\n",
    "\n",
    "Here we normalize the series to lie in the range [0,1] [using this scikit function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), but it is also commonplace to normalize by a series standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### Load in necessary libraries for data input and normalization\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "\n",
    "### load in and normalize the dataset\n",
    "dataset = np.loadtxt('datasets/normalized_apple_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at the (normalized) time series we'll be performing predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11963fef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUrigmJlZKVxQzMysFC4oZmZWiv8D0ajmVqfhrowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1195f2d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets take a look at our time series\n",
    "plt.plot(dataset)\n",
    "plt.xlabel('time period')\n",
    "plt.ylabel('normalized series value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Cutting our time series into sequences\n",
    "\n",
    "Remember, our time series is a sequence of numbers that we can represent in general mathematically as \n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $s_{p}$ is the numerical value of the time series at time period $p$ and where $P$ is the total length of the series.  In order to apply our RNN we treat the time series prediction problem as a regression problem, and so need to use a sliding window to construct a set of associated input/output pairs to regress on.  This process is animated in the gif below.\n",
    "\n",
    "<img src=\"images/timeseries_windowing_training.gif\" width=600 height=600/>\n",
    "\n",
    "For example - using a window of size T = 5 (as illustrated in the gif above) we produce a set of input/output pairs like the one shown in the table below\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of length 4 (and in general has length equal to the window size T) while each corresponding output is a scalar value.  Notice also how given a time series of length P and window size T = 5 as shown above, we created P - 5  input/output pairs.  More generally, for a window size T we create P - T such pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for you to window the input time series as described above!  \n",
    "\n",
    "<a id='TODO_1'></a>\n",
    "\n",
    "**TODO:** Implement the function called **window_transform_series** in my_answers.py so that it runs a sliding window along the input series and creates associated input/output pairs.    Note that this function should input a) the series and b) the window length, and return the input/output subsequences.  Make sure to format returned input/output as generally shown in table above (where window_size = 5), and make sure your returned input is a numpy array.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your function on the list of odd numbers given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odd_nums = np.array([1,3,5,7,9,11,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a hard-coded solution for odd_nums.  You can compare its results with what you get from your **window_transform_series** implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the input X will look like ----\n",
      "[[ 1  3]\n",
      " [ 3  5]\n",
      " [ 5  7]\n",
      " [ 7  9]\n",
      " [ 9 11]\n",
      " [11 13]]\n",
      "--- the associated output y will look like ----\n",
      "[[ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]]\n"
     ]
    }
   ],
   "source": [
    "# run a window of size 2 over the odd number sequence and display the results\n",
    "window_size = 2\n",
    "\n",
    "X = []\n",
    "X.append(odd_nums[0:2])\n",
    "X.append(odd_nums[1:3])\n",
    "X.append(odd_nums[2:4])\n",
    "X.append(odd_nums[3:5])\n",
    "X.append(odd_nums[4:6])\n",
    "X.append(odd_nums[5:7])\n",
    "\n",
    "y = odd_nums[2:]\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "y = np.reshape(y, (len(y),1)) #optional\n",
    "\n",
    "assert(type(X).__name__ == 'ndarray')\n",
    "assert(type(y).__name__ == 'ndarray')\n",
    "assert(X.shape == (6,2))\n",
    "assert(y.shape in [(5,1), (5,)])\n",
    "\n",
    "# print out input/output pairs --> here input = X, corresponding output = y\n",
    "print ('--- the input X will look like ----')\n",
    "print (X)\n",
    "\n",
    "print ('--- the associated output y will look like ----')\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again - you can check that your completed **window_transform_series** function works correctly by trying it on the odd_nums sequence - you should get the above output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: implement the function window_transform_series in the file my_answers.py\n",
    "from my_answers import window_transform_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function in place apply it to the series in the Python cell below.  We use a window_size = 7 for these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window the data using your windowing function\n",
    "window_size = 7\n",
    "X,y = window_transform_series(series = dataset,window_size = window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Splitting into training and testing sets\n",
    "\n",
    "In order to perform proper testing on our dataset we will lop off the last 1/3 of it for validation (or testing).  This is that once we train our model we have something to test it on (like any regression problem!).  This splitting into training/testing sets is done in the cell below.\n",
    "\n",
    "Note how here we are **not** splitting the dataset *randomly* as one typically would do when validating a regression model.  This is because our input/output pairs *are related temporally*.   We don't want to validate our model by training on a random subset of the series and then testing on another random subset, as this simulates the scenario that we receive new points *within the timeframe of our training set*.  \n",
    "\n",
    "We want to train on one solid chunk of the series (in our case, the first full 2/3 of it), and validate on a later chunk (the last 1/3) as this simulates how we would predict *future* values of a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our dataset into training / testing sets\n",
    "train_test_split = int(np.ceil(2*len(y)/float(3)))   # set the split point\n",
    "\n",
    "# partition the training set\n",
    "X_train = X[:train_test_split,:]\n",
    "y_train = y[:train_test_split]\n",
    "\n",
    "# keep the last chunk for testing\n",
    "X_test = X[train_test_split:,:]\n",
    "y_test = y[train_test_split:]\n",
    "\n",
    "# NOTE: to use keras's RNN LSTM module our input must be reshaped to [samples, window size, stepsize] \n",
    "X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
    "X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_2'></a>\n",
    "\n",
    "## 1.4  Build and run an RNN regression model\n",
    "\n",
    "Having created input/output pairs out of our time series and cut this into training/testing sets, we can now begin setting up our RNN.  We use Keras to quickly build a two hidden layer RNN of the following specifications\n",
    "\n",
    "- layer 1 uses an LSTM module with 5 hidden units (note here the input_shape = (window_size,1))\n",
    "- layer 2 uses a fully connected module with one unit\n",
    "- the 'mean_squared_error' loss should be used (remember: we are performing regression here)\n",
    "\n",
    "This can be constructed using just a few lines - see e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LTSM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models.  Make sure you are initializing your optimizer given the [keras-recommended approach for RNNs](https://keras.io/optimizers/) \n",
    "\n",
    "(given in the cell below).  (remember to copy your completed function into the script *my_answers.py* function titled *build_part1_RNN* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "# graph the history of model.fit\n",
    "def show_history_graph(history):\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show() \n",
    "\n",
    "class EpochTimer(keras.callbacks.Callback):\n",
    "    train_start = 0\n",
    "    train_end = 0\n",
    "    epoch_start = 0\n",
    "    epoch_end = 0\n",
    "    \n",
    "    def get_time(self):\n",
    "        return timeit.default_timer()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_start = self.get_time()\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.train_end = self.get_time()\n",
    "        print('Training took {} seconds'.format(self.train_end - self.train_start))\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_start = self.get_time()\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_end = self.get_time()\n",
    "        print('Epoch {} took {} seconds'.format(epoch, self.epoch_end - self.epoch_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: create required RNN model\n",
    "# import keras network libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "\n",
    "# given - fix random seed - so we can all reproduce the same results on our default time series\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# TODO: implement build_part1_RNN in my_answers.py\n",
    "from my_answers import build_part1_RNN\n",
    "model = build_part1_RNN(window_size)\n",
    "\n",
    "# build model using keras documentation recommended optimizer initialization\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your model built you can now fit the model by activating the cell below!  Note: the number of epochs (np_epochs) and batch_size are preset (so we can all produce the same results).  You can choose to toggle the verbose parameter - which gives you regular updates on the progress of the algorithm - on and off by setting it to 1 or 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 took 1.6377807690005284 seconds\n",
      "Epoch 1 took 0.04001410999990185 seconds\n",
      "Epoch 2 took 0.03931243999977596 seconds\n",
      "Epoch 3 took 0.038990518001810415 seconds\n",
      "Epoch 4 took 0.040262883998366306 seconds\n",
      "Epoch 5 took 0.041188535000401316 seconds\n",
      "Epoch 6 took 0.04262087100141798 seconds\n",
      "Epoch 7 took 0.04877839799883077 seconds\n",
      "Epoch 8 took 0.05037483200067072 seconds\n",
      "Epoch 9 took 0.0427142400003504 seconds\n",
      "Epoch 10 took 0.03938167600063025 seconds\n",
      "Epoch 11 took 0.041743683999811765 seconds\n",
      "Epoch 12 took 0.04461281600015354 seconds\n",
      "Epoch 13 took 0.03954650499872514 seconds\n",
      "Epoch 14 took 0.03812814499906381 seconds\n",
      "Epoch 15 took 0.03846108300058404 seconds\n",
      "Epoch 16 took 0.03778689800310531 seconds\n",
      "Epoch 17 took 0.042502291998971486 seconds\n",
      "Epoch 18 took 0.05519142999764881 seconds\n",
      "Epoch 19 took 0.042679783000494353 seconds\n",
      "Epoch 20 took 0.038166930000443244 seconds\n",
      "Epoch 21 took 0.0553937410004437 seconds\n",
      "Epoch 22 took 0.06384158900254988 seconds\n",
      "Epoch 23 took 0.05943325399857713 seconds\n",
      "Epoch 24 took 0.052570059000572655 seconds\n",
      "Epoch 25 took 0.045279808997293 seconds\n",
      "Epoch 26 took 0.03943128299943055 seconds\n",
      "Epoch 27 took 0.04243724299885798 seconds\n",
      "Epoch 28 took 0.04476995300137787 seconds\n",
      "Epoch 29 took 0.03891926600044826 seconds\n",
      "Epoch 30 took 0.041136865998851135 seconds\n",
      "Epoch 31 took 0.040270331999636255 seconds\n",
      "Epoch 32 took 0.04037718700055848 seconds\n",
      "Epoch 33 took 0.04642357699776767 seconds\n",
      "Epoch 34 took 0.04414638300295337 seconds\n",
      "Epoch 35 took 0.03941687800033833 seconds\n",
      "Epoch 36 took 0.04012869799771579 seconds\n",
      "Epoch 37 took 0.040269840999826556 seconds\n",
      "Epoch 38 took 0.04508906699993531 seconds\n",
      "Epoch 39 took 0.04332927299765288 seconds\n",
      "Epoch 40 took 0.037953290000587 seconds\n",
      "Epoch 41 took 0.036987513998610666 seconds\n",
      "Epoch 42 took 0.0373381720019097 seconds\n",
      "Epoch 43 took 0.04177259999778471 seconds\n",
      "Epoch 44 took 0.0438709359987115 seconds\n",
      "Epoch 45 took 0.03737023999929079 seconds\n",
      "Epoch 46 took 0.038441876000433695 seconds\n",
      "Epoch 47 took 0.03885808800259838 seconds\n",
      "Epoch 48 took 0.038751427997340215 seconds\n",
      "Epoch 49 took 0.04208397899856209 seconds\n",
      "Epoch 50 took 0.043608654999843566 seconds\n",
      "Epoch 51 took 0.03788067400091677 seconds\n",
      "Epoch 52 took 0.0376224280007591 seconds\n",
      "Epoch 53 took 0.03721130299891229 seconds\n",
      "Epoch 54 took 0.03928107899992028 seconds\n",
      "Epoch 55 took 0.04222763500001747 seconds\n",
      "Epoch 56 took 0.04287161699903663 seconds\n",
      "Epoch 57 took 0.03813063400230021 seconds\n",
      "Epoch 58 took 0.036077560998819536 seconds\n",
      "Epoch 59 took 0.03585978599949158 seconds\n",
      "Epoch 60 took 0.03670343799967668 seconds\n",
      "Epoch 61 took 0.04087467999852379 seconds\n",
      "Epoch 62 took 0.04257548500027042 seconds\n",
      "Epoch 63 took 0.03913200500028324 seconds\n",
      "Epoch 64 took 0.038120090001029894 seconds\n",
      "Epoch 65 took 0.037486447999981465 seconds\n",
      "Epoch 66 took 0.03692420700099319 seconds\n",
      "Epoch 67 took 0.0413758799986681 seconds\n",
      "Epoch 68 took 0.044020089000696316 seconds\n",
      "Epoch 69 took 0.0393952630001877 seconds\n",
      "Epoch 70 took 0.03884207500232151 seconds\n",
      "Epoch 71 took 0.03952728600052069 seconds\n",
      "Epoch 72 took 0.04372648900243803 seconds\n",
      "Epoch 73 took 0.04365901299752295 seconds\n",
      "Epoch 74 took 0.04483661499762093 seconds\n",
      "Epoch 75 took 0.040884927002480254 seconds\n",
      "Epoch 76 took 0.038964471001236234 seconds\n",
      "Epoch 77 took 0.04084696499921847 seconds\n",
      "Epoch 78 took 0.04403427199940779 seconds\n",
      "Epoch 79 took 0.04326888899959158 seconds\n",
      "Epoch 80 took 0.03776498099978198 seconds\n",
      "Epoch 81 took 0.03885344700029236 seconds\n",
      "Epoch 82 took 0.03843328900256893 seconds\n",
      "Epoch 83 took 0.04232820000106585 seconds\n",
      "Epoch 84 took 0.042318461997638224 seconds\n",
      "Epoch 85 took 0.03732339599810075 seconds\n",
      "Epoch 86 took 0.03652202699959162 seconds\n",
      "Epoch 87 took 0.03708941800141474 seconds\n",
      "Epoch 88 took 0.04342124100003275 seconds\n",
      "Epoch 89 took 0.04538348500136635 seconds\n",
      "Epoch 90 took 0.05469872200046666 seconds\n",
      "Epoch 91 took 0.04617726499782293 seconds\n",
      "Epoch 92 took 0.03671258399845101 seconds\n",
      "Epoch 93 took 0.06458336699870415 seconds\n",
      "Epoch 94 took 0.05039264700099011 seconds\n",
      "Epoch 95 took 0.04340027400030522 seconds\n",
      "Epoch 96 took 0.03889255700050853 seconds\n",
      "Epoch 97 took 0.03705475599781494 seconds\n",
      "Epoch 98 took 0.038027177997719264 seconds\n",
      "Epoch 99 took 0.04339027799869655 seconds\n",
      "Epoch 100 took 0.04595835000145598 seconds\n",
      "Epoch 101 took 0.04045410099934088 seconds\n",
      "Epoch 102 took 0.04460038600154803 seconds\n",
      "Epoch 103 took 0.04194758900121087 seconds\n",
      "Epoch 104 took 0.04654684499837458 seconds\n",
      "Epoch 105 took 0.04420276900054887 seconds\n",
      "Epoch 106 took 0.03890299499835237 seconds\n",
      "Epoch 107 took 0.03795000099853496 seconds\n",
      "Epoch 108 took 0.03937474299891619 seconds\n",
      "Epoch 109 took 0.05044888200063724 seconds\n",
      "Epoch 110 took 0.04257185900132754 seconds\n",
      "Epoch 111 took 0.04487085000073421 seconds\n",
      "Epoch 112 took 0.04506473699802882 seconds\n",
      "Epoch 113 took 0.044126978998974664 seconds\n",
      "Epoch 114 took 0.048672329998225905 seconds\n",
      "Epoch 115 took 0.04711832699831575 seconds\n",
      "Epoch 116 took 0.039407403997756774 seconds\n",
      "Epoch 117 took 0.03669166100007715 seconds\n",
      "Epoch 118 took 0.039873683999758214 seconds\n",
      "Epoch 119 took 0.042405444000905845 seconds\n",
      "Epoch 120 took 0.038363813000614755 seconds\n",
      "Epoch 121 took 0.03867135399923427 seconds\n",
      "Epoch 122 took 0.03633651600102894 seconds\n",
      "Epoch 123 took 0.050390577998769004 seconds\n",
      "Epoch 124 took 0.05171992000032333 seconds\n",
      "Epoch 125 took 0.057557127001928166 seconds\n",
      "Epoch 126 took 0.051928253000369295 seconds\n",
      "Epoch 127 took 0.045084941000823164 seconds\n",
      "Epoch 128 took 0.03904478699769243 seconds\n",
      "Epoch 129 took 0.04153419899739674 seconds\n",
      "Epoch 130 took 0.03878074899694184 seconds\n",
      "Epoch 131 took 0.039931847000843845 seconds\n",
      "Epoch 132 took 0.03997223500118707 seconds\n",
      "Epoch 133 took 0.039015315000142436 seconds\n",
      "Epoch 134 took 0.04893672300022445 seconds\n",
      "Epoch 135 took 0.059552725000685314 seconds\n",
      "Epoch 136 took 0.057313609002449084 seconds\n",
      "Epoch 137 took 0.05835989399929531 seconds\n",
      "Epoch 138 took 0.05709643099908135 seconds\n",
      "Epoch 139 took 0.05797135499960859 seconds\n",
      "Epoch 140 took 0.059710831999836955 seconds\n",
      "Epoch 141 took 0.05533641100191744 seconds\n",
      "Epoch 142 took 0.0441907229978824 seconds\n",
      "Epoch 143 took 0.051582934996986296 seconds\n",
      "Epoch 144 took 0.038691606001520995 seconds\n",
      "Epoch 145 took 0.04309959400052321 seconds\n",
      "Epoch 146 took 0.04085670699714683 seconds\n",
      "Epoch 147 took 0.03732373000093503 seconds\n",
      "Epoch 148 took 0.05399645299985423 seconds\n",
      "Epoch 149 took 0.043146067997440696 seconds\n",
      "Epoch 150 took 0.036908156998833874 seconds\n",
      "Epoch 151 took 0.03786867500093649 seconds\n",
      "Epoch 152 took 0.03739017900079489 seconds\n",
      "Epoch 153 took 0.038488361999043263 seconds\n",
      "Epoch 154 took 0.03698081599941361 seconds\n",
      "Epoch 155 took 0.05123917399760103 seconds\n",
      "Epoch 156 took 0.037685097002395196 seconds\n",
      "Epoch 157 took 0.048365933002060046 seconds\n",
      "Epoch 158 took 0.03826107599888928 seconds\n",
      "Epoch 159 took 0.037306556001567515 seconds\n",
      "Epoch 160 took 0.03671763799866312 seconds\n",
      "Epoch 161 took 0.036758352998731425 seconds\n",
      "Epoch 162 took 0.03716019000057713 seconds\n",
      "Epoch 163 took 0.04722582499744021 seconds\n",
      "Epoch 164 took 0.04177101300228969 seconds\n",
      "Epoch 165 took 0.03983895599958487 seconds\n",
      "Epoch 166 took 0.044529341997986194 seconds\n",
      "Epoch 167 took 0.03736040799776674 seconds\n",
      "Epoch 168 took 0.03891054899941082 seconds\n",
      "Epoch 169 took 0.052443918997596484 seconds\n",
      "Epoch 170 took 0.037524481002037646 seconds\n",
      "Epoch 171 took 0.04723038100200938 seconds\n",
      "Epoch 172 took 0.041847211999993306 seconds\n",
      "Epoch 173 took 0.03779524900164688 seconds\n",
      "Epoch 174 took 0.03655772199999774 seconds\n",
      "Epoch 175 took 0.03704187399853254 seconds\n",
      "Epoch 176 took 0.036902518000715645 seconds\n",
      "Epoch 177 took 0.03605754700038233 seconds\n",
      "Epoch 178 took 0.036236014999303734 seconds\n",
      "Epoch 179 took 0.03731509299905156 seconds\n",
      "Epoch 180 took 0.037163846998737426 seconds\n",
      "Epoch 181 took 0.03670680700088269 seconds\n",
      "Epoch 182 took 0.03690304499832564 seconds\n",
      "Epoch 183 took 0.03743619799934095 seconds\n",
      "Epoch 184 took 0.037634478001564275 seconds\n",
      "Epoch 185 took 0.05156030900252517 seconds\n",
      "Epoch 186 took 0.03824036199875991 seconds\n",
      "Epoch 187 took 0.04831545300112339 seconds\n",
      "Epoch 188 took 0.036600766998162726 seconds\n",
      "Epoch 189 took 0.038159339001140324 seconds\n",
      "Epoch 190 took 0.03730665400144062 seconds\n",
      "Epoch 191 took 0.03698927799996454 seconds\n",
      "Epoch 192 took 0.0391213479997532 seconds\n",
      "Epoch 193 took 0.03758693399868207 seconds\n",
      "Epoch 194 took 0.03643495599681046 seconds\n",
      "Epoch 195 took 0.036207097000442445 seconds\n",
      "Epoch 196 took 0.03617403399766772 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197 took 0.03726186900166795 seconds\n",
      "Epoch 198 took 0.0376911410021421 seconds\n",
      "Epoch 199 took 0.036113766000198666 seconds\n",
      "Epoch 200 took 0.03692277500158525 seconds\n",
      "Epoch 201 took 0.03725199499967857 seconds\n",
      "Epoch 202 took 0.03730934299892397 seconds\n",
      "Epoch 203 took 0.03707323699927656 seconds\n",
      "Epoch 204 took 0.036603451997507364 seconds\n",
      "Epoch 205 took 0.03806597299990244 seconds\n",
      "Epoch 206 took 0.03732055299769854 seconds\n",
      "Epoch 207 took 0.03680614499899093 seconds\n",
      "Epoch 208 took 0.03863185400041402 seconds\n",
      "Epoch 209 took 0.038671156002237694 seconds\n",
      "Epoch 210 took 0.04688621199966292 seconds\n",
      "Epoch 211 took 0.06404250600098749 seconds\n",
      "Epoch 212 took 0.05306110799938324 seconds\n",
      "Epoch 213 took 0.04493083999841474 seconds\n",
      "Epoch 214 took 0.04009364400189952 seconds\n",
      "Epoch 215 took 0.039657092002016725 seconds\n",
      "Epoch 216 took 0.03763144500044291 seconds\n",
      "Epoch 217 took 0.03834236300099292 seconds\n",
      "Epoch 218 took 0.03678637700068066 seconds\n",
      "Epoch 219 took 0.03718366899920511 seconds\n",
      "Epoch 220 took 0.0361801569997624 seconds\n",
      "Epoch 221 took 0.036305585999798495 seconds\n",
      "Epoch 222 took 0.03650168300009682 seconds\n",
      "Epoch 223 took 0.03756772499764338 seconds\n",
      "Epoch 224 took 0.03595897699779016 seconds\n",
      "Epoch 225 took 0.03744593099690974 seconds\n",
      "Epoch 226 took 0.036720488002174534 seconds\n",
      "Epoch 227 took 0.03614189500149223 seconds\n",
      "Epoch 228 took 0.03583700399758527 seconds\n",
      "Epoch 229 took 0.03648934499869938 seconds\n",
      "Epoch 230 took 0.03585263599961763 seconds\n",
      "Epoch 231 took 0.037062956998852314 seconds\n",
      "Epoch 232 took 0.03752001099928748 seconds\n",
      "Epoch 233 took 0.03616629899988766 seconds\n",
      "Epoch 234 took 0.03637409400107572 seconds\n",
      "Epoch 235 took 0.04584441399856587 seconds\n",
      "Epoch 236 took 0.047932637000485556 seconds\n",
      "Epoch 237 took 0.04674647399951937 seconds\n",
      "Epoch 238 took 0.039451826000004075 seconds\n",
      "Epoch 239 took 0.036559929001668934 seconds\n",
      "Epoch 240 took 0.03617858199868351 seconds\n",
      "Epoch 241 took 0.038155685000674566 seconds\n",
      "Epoch 242 took 0.037481830000615446 seconds\n",
      "Epoch 243 took 0.03839212900129496 seconds\n",
      "Epoch 244 took 0.03694208900196827 seconds\n",
      "Epoch 245 took 0.036542360998282675 seconds\n",
      "Epoch 246 took 0.036561127002642024 seconds\n",
      "Epoch 247 took 0.03637843300020904 seconds\n",
      "Epoch 248 took 0.03697479099719203 seconds\n",
      "Epoch 249 took 0.035845442002027994 seconds\n",
      "Epoch 250 took 0.037083522001921665 seconds\n",
      "Epoch 251 took 0.03698806999818771 seconds\n",
      "Epoch 252 took 0.036389546999998856 seconds\n",
      "Epoch 253 took 0.04395411899895407 seconds\n",
      "Epoch 254 took 0.04407528600131627 seconds\n",
      "Epoch 255 took 0.03803017900281702 seconds\n",
      "Epoch 256 took 0.0463527569991129 seconds\n",
      "Epoch 257 took 0.03589811100027873 seconds\n",
      "Epoch 258 took 0.03653033000227879 seconds\n",
      "Epoch 259 took 0.03692008500001975 seconds\n",
      "Epoch 260 took 0.03782190000129049 seconds\n",
      "Epoch 261 took 0.03733551999903284 seconds\n",
      "Epoch 262 took 0.03696949000004679 seconds\n",
      "Epoch 263 took 0.03453454600094119 seconds\n",
      "Epoch 264 took 0.036166439997032285 seconds\n",
      "Epoch 265 took 0.03599933900113683 seconds\n",
      "Epoch 266 took 0.0378034450004634 seconds\n",
      "Epoch 267 took 0.03687411800274276 seconds\n",
      "Epoch 268 took 0.03667758300071 seconds\n",
      "Epoch 269 took 0.03621957899667905 seconds\n",
      "Epoch 270 took 0.03775172000314342 seconds\n",
      "Epoch 271 took 0.035839815998770064 seconds\n",
      "Epoch 272 took 0.037033470998721896 seconds\n",
      "Epoch 273 took 0.03731674400114571 seconds\n",
      "Epoch 274 took 0.03668789299990749 seconds\n",
      "Epoch 275 took 0.03742898900236469 seconds\n",
      "Epoch 276 took 0.035518226999556646 seconds\n",
      "Epoch 277 took 0.03695808200063766 seconds\n",
      "Epoch 278 took 0.03723263499705354 seconds\n",
      "Epoch 279 took 0.03580290500030969 seconds\n",
      "Epoch 280 took 0.03680364399770042 seconds\n",
      "Epoch 281 took 0.03592800200203783 seconds\n",
      "Epoch 282 took 0.03653433499857783 seconds\n",
      "Epoch 283 took 0.03647116200227174 seconds\n",
      "Epoch 284 took 0.03695218799839495 seconds\n",
      "Epoch 285 took 0.03699491099905572 seconds\n",
      "Epoch 286 took 0.03638238200073829 seconds\n",
      "Epoch 287 took 0.036294176999945194 seconds\n",
      "Epoch 288 took 0.03604113999972469 seconds\n",
      "Epoch 289 took 0.0371703710006841 seconds\n",
      "Epoch 290 took 0.03671494700029143 seconds\n",
      "Epoch 291 took 0.03636293900126475 seconds\n",
      "Epoch 292 took 0.036580269999831216 seconds\n",
      "Epoch 293 took 0.04729104400030337 seconds\n",
      "Epoch 294 took 0.04452510400005849 seconds\n",
      "Epoch 295 took 0.04474883800139651 seconds\n",
      "Epoch 296 took 0.044825908000348136 seconds\n",
      "Epoch 297 took 0.03640910800095298 seconds\n",
      "Epoch 298 took 0.037884845998632954 seconds\n",
      "Epoch 299 took 0.03614540800117538 seconds\n",
      "Epoch 300 took 0.036532154997985344 seconds\n",
      "Epoch 301 took 0.03670944099940243 seconds\n",
      "Epoch 302 took 0.037831541998457396 seconds\n",
      "Epoch 303 took 0.036098497999773826 seconds\n",
      "Epoch 304 took 0.036127472998487065 seconds\n",
      "Epoch 305 took 0.03593820400055847 seconds\n",
      "Epoch 306 took 0.03744135099987034 seconds\n",
      "Epoch 307 took 0.03699025099922437 seconds\n",
      "Epoch 308 took 0.03635850999853574 seconds\n",
      "Epoch 309 took 0.036633717001677724 seconds\n",
      "Epoch 310 took 0.03652125999724376 seconds\n",
      "Epoch 311 took 0.036448328999540536 seconds\n",
      "Epoch 312 took 0.036405493003258016 seconds\n",
      "Epoch 313 took 0.03648443900237908 seconds\n",
      "Epoch 314 took 0.03684314299971447 seconds\n",
      "Epoch 315 took 0.03681550699911895 seconds\n",
      "Epoch 316 took 0.03582684499997413 seconds\n",
      "Epoch 317 took 0.037893082000664435 seconds\n",
      "Epoch 318 took 0.036082953000004636 seconds\n",
      "Epoch 319 took 0.036897964997478994 seconds\n",
      "Epoch 320 took 0.03671524499804946 seconds\n",
      "Epoch 321 took 0.0363733369995316 seconds\n",
      "Epoch 322 took 0.03673879399866564 seconds\n",
      "Epoch 323 took 0.038653157997032395 seconds\n",
      "Epoch 324 took 0.037992424997355556 seconds\n",
      "Epoch 325 took 0.03772165200280142 seconds\n",
      "Epoch 326 took 0.03661174200169626 seconds\n",
      "Epoch 327 took 0.03750551999837626 seconds\n",
      "Epoch 328 took 0.03660961000059615 seconds\n",
      "Epoch 329 took 0.03728493299786351 seconds\n",
      "Epoch 330 took 0.03616393500124104 seconds\n",
      "Epoch 331 took 0.03737589500087779 seconds\n",
      "Epoch 332 took 0.036300422998465365 seconds\n",
      "Epoch 333 took 0.037639563997799996 seconds\n",
      "Epoch 334 took 0.04083977800110006 seconds\n",
      "Epoch 335 took 0.03832427499946789 seconds\n",
      "Epoch 336 took 0.037227114000415895 seconds\n",
      "Epoch 337 took 0.0371770359997754 seconds\n",
      "Epoch 338 took 0.03749668099771952 seconds\n",
      "Epoch 339 took 0.038369723999494454 seconds\n",
      "Epoch 340 took 0.036935791998985223 seconds\n",
      "Epoch 341 took 0.04191117799928179 seconds\n",
      "Epoch 342 took 0.04386995200184174 seconds\n",
      "Epoch 343 took 0.04384976999790524 seconds\n",
      "Epoch 344 took 0.0412165929992625 seconds\n",
      "Epoch 345 took 0.04119359299875214 seconds\n",
      "Epoch 346 took 0.03885674399862182 seconds\n",
      "Epoch 347 took 0.037319581999327056 seconds\n",
      "Epoch 348 took 0.037012654000136536 seconds\n",
      "Epoch 349 took 0.03886489199794596 seconds\n",
      "Epoch 350 took 0.03829389499878744 seconds\n",
      "Epoch 351 took 0.03653919899807079 seconds\n",
      "Epoch 352 took 0.0382854910021706 seconds\n",
      "Epoch 353 took 0.036769494003237924 seconds\n",
      "Epoch 354 took 0.03652756899828091 seconds\n",
      "Epoch 355 took 0.04043082600037451 seconds\n",
      "Epoch 356 took 0.036091713001951575 seconds\n",
      "Epoch 357 took 0.03671623999980511 seconds\n",
      "Epoch 358 took 0.03710777599917492 seconds\n",
      "Epoch 359 took 0.0367814150013146 seconds\n",
      "Epoch 360 took 0.03642932799994014 seconds\n",
      "Epoch 361 took 0.037342276002164 seconds\n",
      "Epoch 362 took 0.03770848400017712 seconds\n",
      "Epoch 363 took 0.03826473599838209 seconds\n",
      "Epoch 364 took 0.039673977000347804 seconds\n",
      "Epoch 365 took 0.03817334199993638 seconds\n",
      "Epoch 366 took 0.0397136710016639 seconds\n",
      "Epoch 367 took 0.03944789599700016 seconds\n",
      "Epoch 368 took 0.038093327999376925 seconds\n",
      "Epoch 369 took 0.03753639199931058 seconds\n",
      "Epoch 370 took 0.03662356099812314 seconds\n",
      "Epoch 371 took 0.04517751199819031 seconds\n",
      "Epoch 372 took 0.0417529510013992 seconds\n",
      "Epoch 373 took 0.038490172002639156 seconds\n",
      "Epoch 374 took 0.03649040999880526 seconds\n",
      "Epoch 375 took 0.03800168399902759 seconds\n",
      "Epoch 376 took 0.03702182499910123 seconds\n",
      "Epoch 377 took 0.037305702000594465 seconds\n",
      "Epoch 378 took 0.03665847199954442 seconds\n",
      "Epoch 379 took 0.03838670199911576 seconds\n",
      "Epoch 380 took 0.036543492002238054 seconds\n",
      "Epoch 381 took 0.036516320000373526 seconds\n",
      "Epoch 382 took 0.03651896199880866 seconds\n",
      "Epoch 383 took 0.03676914400057285 seconds\n",
      "Epoch 384 took 0.03599767199921189 seconds\n",
      "Epoch 385 took 0.03750815400053398 seconds\n",
      "Epoch 386 took 0.03739007700278307 seconds\n",
      "Epoch 387 took 0.03630228700058069 seconds\n",
      "Epoch 388 took 0.03630631899795844 seconds\n",
      "Epoch 389 took 0.03697039799953927 seconds\n",
      "Epoch 390 took 0.03617268900052295 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391 took 0.0367566530003387 seconds\n",
      "Epoch 392 took 0.03567535299953306 seconds\n",
      "Epoch 393 took 0.036487077002675505 seconds\n",
      "Epoch 394 took 0.03645982099988032 seconds\n",
      "Epoch 395 took 0.03678102399862837 seconds\n",
      "Epoch 396 took 0.0369700829978683 seconds\n",
      "Epoch 397 took 0.037757657999463845 seconds\n",
      "Epoch 398 took 0.03743815000052564 seconds\n",
      "Epoch 399 took 0.037436144000821514 seconds\n",
      "Epoch 400 took 0.03574934999778634 seconds\n",
      "Epoch 401 took 0.03639453600044362 seconds\n",
      "Epoch 402 took 0.03734505900138174 seconds\n",
      "Epoch 403 took 0.03824995300237788 seconds\n",
      "Epoch 404 took 0.03847796899935929 seconds\n",
      "Epoch 405 took 0.03737378000005265 seconds\n",
      "Epoch 406 took 0.03687822099891491 seconds\n",
      "Epoch 407 took 0.038644819000182906 seconds\n",
      "Epoch 408 took 0.039005337999697076 seconds\n",
      "Epoch 409 took 0.03895917599948007 seconds\n",
      "Epoch 410 took 0.040150962999177864 seconds\n",
      "Epoch 411 took 0.037913506999757374 seconds\n",
      "Epoch 412 took 0.03965432599943597 seconds\n",
      "Epoch 413 took 0.03742340799726662 seconds\n",
      "Epoch 414 took 0.037157285998546286 seconds\n",
      "Epoch 415 took 0.036614612999983365 seconds\n",
      "Epoch 416 took 0.03641446999972686 seconds\n",
      "Epoch 417 took 0.03688296600012109 seconds\n",
      "Epoch 418 took 0.03713707100177999 seconds\n",
      "Epoch 419 took 0.03827928299870109 seconds\n",
      "Epoch 420 took 0.038672701997711556 seconds\n",
      "Epoch 421 took 0.039763306001987075 seconds\n",
      "Epoch 422 took 0.0387869430014689 seconds\n",
      "Epoch 423 took 0.038898308001080295 seconds\n",
      "Epoch 424 took 0.03693950700107962 seconds\n",
      "Epoch 425 took 0.03968259999965085 seconds\n",
      "Epoch 426 took 0.04217388999677496 seconds\n",
      "Epoch 427 took 0.03801776299951598 seconds\n",
      "Epoch 428 took 0.036843111000052886 seconds\n",
      "Epoch 429 took 0.03999285499958205 seconds\n",
      "Epoch 430 took 0.04101612500016927 seconds\n",
      "Epoch 431 took 0.03886804200010374 seconds\n",
      "Epoch 432 took 0.038501733000885 seconds\n",
      "Epoch 433 took 0.04024450199722196 seconds\n",
      "Epoch 434 took 0.04002056500030449 seconds\n",
      "Epoch 435 took 0.03799468999932287 seconds\n",
      "Epoch 436 took 0.039704037000774406 seconds\n",
      "Epoch 437 took 0.039252876998943975 seconds\n",
      "Epoch 438 took 0.038521030997799244 seconds\n",
      "Epoch 439 took 0.038948411001911154 seconds\n",
      "Epoch 440 took 0.038747931001125835 seconds\n",
      "Epoch 441 took 0.0428941179998219 seconds\n",
      "Epoch 442 took 0.045138662000681506 seconds\n",
      "Epoch 443 took 0.041091805996984476 seconds\n",
      "Epoch 444 took 0.039089980000426294 seconds\n",
      "Epoch 445 took 0.037838288000784814 seconds\n",
      "Epoch 446 took 0.03736432300138404 seconds\n",
      "Epoch 447 took 0.036494757998298155 seconds\n",
      "Epoch 448 took 0.03638305499771377 seconds\n",
      "Epoch 449 took 0.036453749002248514 seconds\n",
      "Epoch 450 took 0.03853166599947144 seconds\n",
      "Epoch 451 took 0.0374561660028121 seconds\n",
      "Epoch 452 took 0.03557677199933096 seconds\n",
      "Epoch 453 took 0.0371996850008145 seconds\n",
      "Epoch 454 took 0.037334848999307724 seconds\n",
      "Epoch 455 took 0.04010022700094851 seconds\n",
      "Epoch 456 took 0.03736162000132026 seconds\n",
      "Epoch 457 took 0.03647734900005162 seconds\n",
      "Epoch 458 took 0.03699513199899229 seconds\n",
      "Epoch 459 took 0.03639546900012647 seconds\n",
      "Epoch 460 took 0.03727631899892003 seconds\n",
      "Epoch 461 took 0.036215027001162525 seconds\n",
      "Epoch 462 took 0.03633955099940067 seconds\n",
      "Epoch 463 took 0.03684697599965148 seconds\n",
      "Epoch 464 took 0.03693950099841459 seconds\n",
      "Epoch 465 took 0.03544976700140978 seconds\n",
      "Epoch 466 took 0.03731091399822617 seconds\n",
      "Epoch 467 took 0.03662292300214176 seconds\n",
      "Epoch 468 took 0.03670858699842938 seconds\n",
      "Epoch 469 took 0.04278349100059131 seconds\n",
      "Epoch 470 took 0.039938993999385275 seconds\n",
      "Epoch 471 took 0.03564510399883147 seconds\n",
      "Epoch 472 took 0.036826621002546744 seconds\n",
      "Epoch 473 took 0.042264566000085324 seconds\n",
      "Epoch 474 took 0.03767729199898895 seconds\n",
      "Epoch 475 took 0.03605828099898645 seconds\n",
      "Epoch 476 took 0.0364698489975126 seconds\n",
      "Epoch 477 took 0.03715139699852443 seconds\n",
      "Epoch 478 took 0.03588941999987583 seconds\n",
      "Epoch 479 took 0.03604298000209383 seconds\n",
      "Epoch 480 took 0.03745440299826441 seconds\n",
      "Epoch 481 took 0.038265537998086074 seconds\n",
      "Epoch 482 took 0.03797694299646537 seconds\n",
      "Epoch 483 took 0.036089785000513075 seconds\n",
      "Epoch 484 took 0.039775525001459755 seconds\n",
      "Epoch 485 took 0.03648690300178714 seconds\n",
      "Epoch 486 took 0.04202765200170688 seconds\n",
      "Epoch 487 took 0.043843497998750536 seconds\n",
      "Epoch 488 took 0.038990633001958486 seconds\n",
      "Epoch 489 took 0.05148233900035848 seconds\n",
      "Epoch 490 took 0.05316297100216616 seconds\n",
      "Epoch 491 took 0.04810872899906826 seconds\n",
      "Epoch 492 took 0.047917149000568315 seconds\n",
      "Epoch 493 took 0.043830492002598476 seconds\n",
      "Epoch 494 took 0.039382332000968745 seconds\n",
      "Epoch 495 took 0.038452058000984835 seconds\n",
      "Epoch 496 took 0.045757072999549564 seconds\n",
      "Epoch 497 took 0.04034292600044864 seconds\n",
      "Epoch 498 took 0.040609842999401735 seconds\n",
      "Epoch 499 took 0.038601399999606656 seconds\n",
      "Epoch 500 took 0.03739284800030873 seconds\n",
      "Epoch 501 took 0.037470025999937207 seconds\n",
      "Epoch 502 took 0.048536113998125074 seconds\n",
      "Epoch 503 took 0.0519403800026339 seconds\n",
      "Epoch 504 took 0.05708610099827638 seconds\n",
      "Epoch 505 took 0.04750022899679607 seconds\n",
      "Epoch 506 took 0.04626781399929314 seconds\n",
      "Epoch 507 took 0.046196983003028436 seconds\n",
      "Epoch 508 took 0.04379861599954893 seconds\n",
      "Epoch 509 took 0.04811078000057023 seconds\n",
      "Epoch 510 took 0.0461496759999136 seconds\n",
      "Epoch 511 took 0.04365545899781864 seconds\n",
      "Epoch 512 took 0.043533625997952186 seconds\n",
      "Epoch 513 took 0.043572130001848564 seconds\n",
      "Epoch 514 took 0.04375761700066505 seconds\n",
      "Epoch 515 took 0.04653391899773851 seconds\n",
      "Epoch 516 took 0.04300188300112495 seconds\n",
      "Epoch 517 took 0.046478277999995044 seconds\n",
      "Epoch 518 took 0.04764148600224871 seconds\n",
      "Epoch 519 took 0.03793628800121951 seconds\n",
      "Epoch 520 took 0.038185081000847276 seconds\n",
      "Epoch 521 took 0.0392026950030413 seconds\n",
      "Epoch 522 took 0.040714553997531766 seconds\n",
      "Epoch 523 took 0.0349658509985602 seconds\n",
      "Epoch 524 took 0.03732038499947521 seconds\n",
      "Epoch 525 took 0.03787189600188867 seconds\n",
      "Epoch 526 took 0.039588375999301206 seconds\n",
      "Epoch 527 took 0.039661762999458006 seconds\n",
      "Epoch 528 took 0.038797004002844915 seconds\n",
      "Epoch 529 took 0.03649733599741012 seconds\n",
      "Epoch 530 took 0.037647053999535274 seconds\n",
      "Epoch 531 took 0.04366408599889837 seconds\n",
      "Epoch 532 took 0.03793485600181157 seconds\n",
      "Epoch 533 took 0.038101774000097066 seconds\n",
      "Epoch 534 took 0.03870498600008432 seconds\n",
      "Epoch 535 took 0.04113202399821603 seconds\n",
      "Epoch 536 took 0.04032283700144035 seconds\n",
      "Epoch 537 took 0.037698633001127746 seconds\n",
      "Epoch 538 took 0.040540665002481546 seconds\n",
      "Epoch 539 took 0.042360516999906395 seconds\n",
      "Epoch 540 took 0.040068248999887146 seconds\n",
      "Epoch 541 took 0.038219358000787906 seconds\n",
      "Epoch 542 took 0.03856325900051161 seconds\n",
      "Epoch 543 took 0.04130895399794099 seconds\n",
      "Epoch 544 took 0.03969615800087922 seconds\n",
      "Epoch 545 took 0.03803211599733913 seconds\n",
      "Epoch 546 took 0.037721802000305615 seconds\n",
      "Epoch 547 took 0.040730684999289224 seconds\n",
      "Epoch 548 took 0.042520585000602296 seconds\n",
      "Epoch 549 took 0.036962946000130614 seconds\n",
      "Epoch 550 took 0.037447839000378735 seconds\n",
      "Epoch 551 took 0.04009887299980619 seconds\n",
      "Epoch 552 took 0.043618626998068066 seconds\n",
      "Epoch 553 took 0.03887857899826486 seconds\n",
      "Epoch 554 took 0.03817759600133286 seconds\n",
      "Epoch 555 took 0.03837798200038378 seconds\n",
      "Epoch 556 took 0.04567734300144366 seconds\n",
      "Epoch 557 took 0.03881466099846875 seconds\n",
      "Epoch 558 took 0.037070419999508886 seconds\n",
      "Epoch 559 took 0.04092104799929075 seconds\n",
      "Epoch 560 took 0.04162252500100294 seconds\n",
      "Epoch 561 took 0.039718976000585826 seconds\n",
      "Epoch 562 took 0.037312306001695106 seconds\n",
      "Epoch 563 took 0.037208109999482986 seconds\n",
      "Epoch 564 took 0.03949758100134204 seconds\n",
      "Epoch 565 took 0.04498556299949996 seconds\n",
      "Epoch 566 took 0.03726604099938413 seconds\n",
      "Epoch 567 took 0.03651283900035196 seconds\n",
      "Epoch 568 took 0.040037988997937646 seconds\n",
      "Epoch 569 took 0.04283965699869441 seconds\n",
      "Epoch 570 took 0.03971596600240446 seconds\n",
      "Epoch 571 took 0.03776848100096686 seconds\n",
      "Epoch 572 took 0.03818260200205259 seconds\n",
      "Epoch 573 took 0.03748710899890284 seconds\n",
      "Epoch 574 took 0.04270165799971437 seconds\n",
      "Epoch 575 took 0.0393002359996899 seconds\n",
      "Epoch 576 took 0.037811898000654764 seconds\n",
      "Epoch 577 took 0.03698101000190945 seconds\n",
      "Epoch 578 took 0.04379623699787771 seconds\n",
      "Epoch 579 took 0.03727356400122517 seconds\n",
      "Epoch 580 took 0.04124864900222747 seconds\n",
      "Epoch 581 took 0.03728252499786322 seconds\n",
      "Epoch 582 took 0.03710068700092961 seconds\n",
      "Epoch 583 took 0.035809518998576095 seconds\n",
      "Epoch 584 took 0.042111621998628834 seconds\n",
      "Epoch 585 took 0.03686711599948467 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 586 took 0.037531169000430964 seconds\n",
      "Epoch 587 took 0.03667821300041396 seconds\n",
      "Epoch 588 took 0.036564415000611916 seconds\n",
      "Epoch 589 took 0.03634561999933794 seconds\n",
      "Epoch 590 took 0.036972597998101264 seconds\n",
      "Epoch 591 took 0.0373803369984671 seconds\n",
      "Epoch 592 took 0.03635986299923388 seconds\n",
      "Epoch 593 took 0.03663185900222743 seconds\n",
      "Epoch 594 took 0.03531107399976463 seconds\n",
      "Epoch 595 took 0.03649459300140734 seconds\n",
      "Epoch 596 took 0.036638222001784015 seconds\n",
      "Epoch 597 took 0.03829836400109343 seconds\n",
      "Epoch 598 took 0.03692461000173353 seconds\n",
      "Epoch 599 took 0.03604976399947191 seconds\n",
      "Epoch 600 took 0.03638608400069643 seconds\n",
      "Epoch 601 took 0.03623706199869048 seconds\n",
      "Epoch 602 took 0.03768293199755135 seconds\n",
      "Epoch 603 took 0.03600181399815483 seconds\n",
      "Epoch 604 took 0.036500220998277655 seconds\n",
      "Epoch 605 took 0.03728000499904738 seconds\n",
      "Epoch 606 took 0.037333943000703584 seconds\n",
      "Epoch 607 took 0.035878755999874556 seconds\n",
      "Epoch 608 took 0.03677464100110228 seconds\n",
      "Epoch 609 took 0.03602908600078081 seconds\n",
      "Epoch 610 took 0.03775091499846894 seconds\n",
      "Epoch 611 took 0.03665171100146836 seconds\n",
      "Epoch 612 took 0.036591448999388376 seconds\n",
      "Epoch 613 took 0.037139494001166895 seconds\n",
      "Epoch 614 took 0.03641029800201068 seconds\n",
      "Epoch 615 took 0.03642664699873421 seconds\n",
      "Epoch 616 took 0.036437501999898814 seconds\n",
      "Epoch 617 took 0.03664003999801935 seconds\n",
      "Epoch 618 took 0.036640401998738525 seconds\n",
      "Epoch 619 took 0.036373167000419926 seconds\n",
      "Epoch 620 took 0.036264963000576245 seconds\n",
      "Epoch 621 took 0.038286942999548046 seconds\n",
      "Epoch 622 took 0.03757154299819376 seconds\n",
      "Epoch 623 took 0.03618249899955117 seconds\n",
      "Epoch 624 took 0.03710965999925975 seconds\n",
      "Epoch 625 took 0.03587720299765351 seconds\n",
      "Epoch 626 took 0.036733705001097405 seconds\n",
      "Epoch 627 took 0.0363550080001005 seconds\n",
      "Epoch 628 took 0.03636853600255563 seconds\n",
      "Epoch 629 took 0.03545745300289127 seconds\n",
      "Epoch 630 took 0.0369168860015634 seconds\n",
      "Epoch 631 took 0.03705888100012089 seconds\n",
      "Epoch 632 took 0.0374851580018003 seconds\n",
      "Epoch 633 took 0.037705170001572696 seconds\n",
      "Epoch 634 took 0.03668580299927271 seconds\n",
      "Epoch 635 took 0.03655071400135057 seconds\n",
      "Epoch 636 took 0.03612606899696402 seconds\n",
      "Epoch 637 took 0.0357597389993316 seconds\n",
      "Epoch 638 took 0.03552749400114408 seconds\n",
      "Epoch 639 took 0.03687384899967583 seconds\n",
      "Epoch 640 took 0.0365392099993187 seconds\n",
      "Epoch 641 took 0.03569884999888018 seconds\n",
      "Epoch 642 took 0.0365614309994271 seconds\n",
      "Epoch 643 took 0.03694563899989589 seconds\n",
      "Epoch 644 took 0.03624947899879771 seconds\n",
      "Epoch 645 took 0.03633051200085902 seconds\n",
      "Epoch 646 took 0.037112517002242384 seconds\n",
      "Epoch 647 took 0.03647553200062248 seconds\n",
      "Epoch 648 took 0.03659074600000167 seconds\n",
      "Epoch 649 took 0.03585824000037974 seconds\n",
      "Epoch 650 took 0.0364909389973036 seconds\n",
      "Epoch 651 took 0.037527046999457525 seconds\n",
      "Epoch 652 took 0.03666515200166032 seconds\n",
      "Epoch 653 took 0.03693049299909035 seconds\n",
      "Epoch 654 took 0.03835501200228464 seconds\n",
      "Epoch 655 took 0.03585969100095099 seconds\n",
      "Epoch 656 took 0.03685704799863743 seconds\n",
      "Epoch 657 took 0.03681339200193179 seconds\n",
      "Epoch 658 took 0.036643632000050275 seconds\n",
      "Epoch 659 took 0.0358686800027499 seconds\n",
      "Epoch 660 took 0.038789714002632536 seconds\n",
      "Epoch 661 took 0.03724104900175007 seconds\n",
      "Epoch 662 took 0.03629380300117191 seconds\n",
      "Epoch 663 took 0.0370440980004787 seconds\n",
      "Epoch 664 took 0.03694474599979003 seconds\n",
      "Epoch 665 took 0.036172232998069376 seconds\n",
      "Epoch 666 took 0.037128205000044545 seconds\n",
      "Epoch 667 took 0.03596142999958829 seconds\n",
      "Epoch 668 took 0.035361793001357 seconds\n",
      "Epoch 669 took 0.03682036399914068 seconds\n",
      "Epoch 670 took 0.03719514000113122 seconds\n",
      "Epoch 671 took 0.03635614999802783 seconds\n",
      "Epoch 672 took 0.03584712500014575 seconds\n",
      "Epoch 673 took 0.035655927000334486 seconds\n",
      "Epoch 674 took 0.036714352001581574 seconds\n",
      "Epoch 675 took 0.036423379999177996 seconds\n",
      "Epoch 676 took 0.037420422999275615 seconds\n",
      "Epoch 677 took 0.036817416999838315 seconds\n",
      "Epoch 678 took 0.03683700199690065 seconds\n",
      "Epoch 679 took 0.03851655399921583 seconds\n",
      "Epoch 680 took 0.0363270449997799 seconds\n",
      "Epoch 681 took 0.036474004002229776 seconds\n",
      "Epoch 682 took 0.036698225998407 seconds\n",
      "Epoch 683 took 0.036465635002969066 seconds\n",
      "Epoch 684 took 0.035925670999858994 seconds\n",
      "Epoch 685 took 0.03548080800101161 seconds\n",
      "Epoch 686 took 0.03671100400242722 seconds\n",
      "Epoch 687 took 0.03856728299797396 seconds\n",
      "Epoch 688 took 0.03718900899912114 seconds\n",
      "Epoch 689 took 0.036611587998777395 seconds\n",
      "Epoch 690 took 0.03542509800172411 seconds\n",
      "Epoch 691 took 0.03613800599850947 seconds\n",
      "Epoch 692 took 0.03665532100058044 seconds\n",
      "Epoch 693 took 0.03610404899882269 seconds\n",
      "Epoch 694 took 0.03701652599920635 seconds\n",
      "Epoch 695 took 0.036688987998786615 seconds\n",
      "Epoch 696 took 0.036857171999145066 seconds\n",
      "Epoch 697 took 0.035729461000300944 seconds\n",
      "Epoch 698 took 0.03611225500208093 seconds\n",
      "Epoch 699 took 0.036564767000527354 seconds\n",
      "Epoch 700 took 0.03756500799863716 seconds\n",
      "Epoch 701 took 0.036639027999626705 seconds\n",
      "Epoch 702 took 0.03544542899908265 seconds\n",
      "Epoch 703 took 0.037106074996700045 seconds\n",
      "Epoch 704 took 0.03627971500100102 seconds\n",
      "Epoch 705 took 0.03607947699856595 seconds\n",
      "Epoch 706 took 0.03743341200242867 seconds\n",
      "Epoch 707 took 0.036703703000966925 seconds\n",
      "Epoch 708 took 0.03683967599863536 seconds\n",
      "Epoch 709 took 0.03751107200150727 seconds\n",
      "Epoch 710 took 0.036778921999939485 seconds\n",
      "Epoch 711 took 0.03563641300206655 seconds\n",
      "Epoch 712 took 0.03689254200071446 seconds\n",
      "Epoch 713 took 0.03562109300037264 seconds\n",
      "Epoch 714 took 0.037059761001728475 seconds\n",
      "Epoch 715 took 0.03908848799983389 seconds\n",
      "Epoch 716 took 0.03644822700152872 seconds\n",
      "Epoch 717 took 0.035782342001766665 seconds\n",
      "Epoch 718 took 0.036646930002461886 seconds\n",
      "Epoch 719 took 0.03748698799972772 seconds\n",
      "Epoch 720 took 0.03639114600082394 seconds\n",
      "Epoch 721 took 0.036810946996411076 seconds\n",
      "Epoch 722 took 0.03649176399994758 seconds\n",
      "Epoch 723 took 0.03654241500044009 seconds\n",
      "Epoch 724 took 0.037530329998844536 seconds\n",
      "Epoch 725 took 0.03591725300066173 seconds\n",
      "Epoch 726 took 0.03580521199910436 seconds\n",
      "Epoch 727 took 0.03664667699922575 seconds\n",
      "Epoch 728 took 0.03791283600003226 seconds\n",
      "Epoch 729 took 0.03880007000043406 seconds\n",
      "Epoch 730 took 0.03697466700032237 seconds\n",
      "Epoch 731 took 0.03682604599816841 seconds\n",
      "Epoch 732 took 0.03788863199952175 seconds\n",
      "Epoch 733 took 0.039216830002260394 seconds\n",
      "Epoch 734 took 0.0380281420002575 seconds\n",
      "Epoch 735 took 0.03881433000060497 seconds\n",
      "Epoch 736 took 0.03909755099812173 seconds\n",
      "Epoch 737 took 0.03964722099772189 seconds\n",
      "Epoch 738 took 0.0396478010006831 seconds\n",
      "Epoch 739 took 0.03993474999879254 seconds\n",
      "Epoch 740 took 0.038174474000697955 seconds\n",
      "Epoch 741 took 0.040470650001225295 seconds\n",
      "Epoch 742 took 0.039064724998752354 seconds\n",
      "Epoch 743 took 0.038775180000811815 seconds\n",
      "Epoch 744 took 0.038489479000418214 seconds\n",
      "Epoch 745 took 0.04083271299896296 seconds\n",
      "Epoch 746 took 0.03871137999885832 seconds\n",
      "Epoch 747 took 0.038674852999974973 seconds\n",
      "Epoch 748 took 0.03982263299985789 seconds\n",
      "Epoch 749 took 0.03964041899962467 seconds\n",
      "Epoch 750 took 0.038964680999924894 seconds\n",
      "Epoch 751 took 0.03656932599915308 seconds\n",
      "Epoch 752 took 0.0358857569990505 seconds\n",
      "Epoch 753 took 0.03650478399868007 seconds\n",
      "Epoch 754 took 0.03770865799742751 seconds\n",
      "Epoch 755 took 0.03702937900015968 seconds\n",
      "Epoch 756 took 0.035926426000514766 seconds\n",
      "Epoch 757 took 0.036786728000151925 seconds\n",
      "Epoch 758 took 0.03663166699698195 seconds\n",
      "Epoch 759 took 0.036826037998253014 seconds\n",
      "Epoch 760 took 0.037018470000475645 seconds\n",
      "Epoch 761 took 0.03625380500307074 seconds\n",
      "Epoch 762 took 0.036235786999895936 seconds\n",
      "Epoch 763 took 0.037013573997683125 seconds\n",
      "Epoch 764 took 0.036990611002693186 seconds\n",
      "Epoch 765 took 0.03632778800238157 seconds\n",
      "Epoch 766 took 0.03729331500289845 seconds\n",
      "Epoch 767 took 0.038173695997102186 seconds\n",
      "Epoch 768 took 0.03719845600062399 seconds\n",
      "Epoch 769 took 0.036467238001932856 seconds\n",
      "Epoch 770 took 0.03674386599959689 seconds\n",
      "Epoch 771 took 0.03702946999692358 seconds\n",
      "Epoch 772 took 0.038303307999740355 seconds\n",
      "Epoch 773 took 0.03785694299949682 seconds\n",
      "Epoch 774 took 0.03753939899979741 seconds\n",
      "Epoch 775 took 0.03642738200142048 seconds\n",
      "Epoch 776 took 0.03645647699886467 seconds\n",
      "Epoch 777 took 0.03627690199937206 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778 took 0.03775980199861806 seconds\n",
      "Epoch 779 took 0.03638554200006183 seconds\n",
      "Epoch 780 took 0.036742669999512145 seconds\n",
      "Epoch 781 took 0.036268093001126545 seconds\n",
      "Epoch 782 took 0.03627974100163556 seconds\n",
      "Epoch 783 took 0.0366605109993543 seconds\n",
      "Epoch 784 took 0.03757210099865915 seconds\n",
      "Epoch 785 took 0.037697005001973594 seconds\n",
      "Epoch 786 took 0.036762799998541595 seconds\n",
      "Epoch 787 took 0.036341757000627695 seconds\n",
      "Epoch 788 took 0.03695972700006678 seconds\n",
      "Epoch 789 took 0.037180407998675946 seconds\n",
      "Epoch 790 took 0.036901874002069235 seconds\n",
      "Epoch 791 took 0.037479810998775065 seconds\n",
      "Epoch 792 took 0.036276441998779774 seconds\n",
      "Epoch 793 took 0.03631355499965139 seconds\n",
      "Epoch 794 took 0.03762420400016708 seconds\n",
      "Epoch 795 took 0.03788832799909869 seconds\n",
      "Epoch 796 took 0.03618114300115849 seconds\n",
      "Epoch 797 took 0.03796142699866323 seconds\n",
      "Epoch 798 took 0.03609908599901246 seconds\n",
      "Epoch 799 took 0.03712256400103797 seconds\n",
      "Epoch 800 took 0.035970398002973525 seconds\n",
      "Epoch 801 took 0.038393081002141116 seconds\n",
      "Epoch 802 took 0.037979584998538485 seconds\n",
      "Epoch 803 took 0.0367095409965259 seconds\n",
      "Epoch 804 took 0.03662324700053432 seconds\n",
      "Epoch 805 took 0.036693245001515606 seconds\n",
      "Epoch 806 took 0.03731720699943253 seconds\n",
      "Epoch 807 took 0.036246240000764374 seconds\n",
      "Epoch 808 took 0.037289087998942705 seconds\n",
      "Epoch 809 took 0.036190421000355855 seconds\n",
      "Epoch 810 took 0.036250125001970446 seconds\n",
      "Epoch 811 took 0.036723537003126694 seconds\n",
      "Epoch 812 took 0.03596762199958903 seconds\n",
      "Epoch 813 took 0.037654503001249395 seconds\n",
      "Epoch 814 took 0.03679629599719192 seconds\n",
      "Epoch 815 took 0.03629244900002959 seconds\n",
      "Epoch 816 took 0.03629874200123595 seconds\n",
      "Epoch 817 took 0.036632839000958484 seconds\n",
      "Epoch 818 took 0.03701973699935479 seconds\n",
      "Epoch 819 took 0.037612395997712156 seconds\n",
      "Epoch 820 took 0.03822550399854663 seconds\n",
      "Epoch 821 took 0.037675839997973526 seconds\n",
      "Epoch 822 took 0.03819629999998142 seconds\n",
      "Epoch 823 took 0.036500717000308214 seconds\n",
      "Epoch 824 took 0.036274948997743195 seconds\n",
      "Epoch 825 took 0.035721766002097866 seconds\n",
      "Epoch 826 took 0.036946732998330845 seconds\n",
      "Epoch 827 took 0.03686328500043601 seconds\n",
      "Epoch 828 took 0.036748146998434095 seconds\n",
      "Epoch 829 took 0.037437312999827554 seconds\n",
      "Epoch 830 took 0.03598408399921027 seconds\n",
      "Epoch 831 took 0.03682811299950117 seconds\n",
      "Epoch 832 took 0.037701389999710955 seconds\n",
      "Epoch 833 took 0.03645785100161447 seconds\n",
      "Epoch 834 took 0.037496992998057976 seconds\n",
      "Epoch 835 took 0.03728369400050724 seconds\n",
      "Epoch 836 took 0.0373851830008789 seconds\n",
      "Epoch 837 took 0.03866404899963527 seconds\n",
      "Epoch 838 took 0.04526708699995652 seconds\n",
      "Epoch 839 took 0.04292324800189817 seconds\n",
      "Epoch 840 took 0.04034726499958197 seconds\n",
      "Epoch 841 took 0.039871712997410214 seconds\n",
      "Epoch 842 took 0.03745950799930142 seconds\n",
      "Epoch 843 took 0.0364516179979546 seconds\n",
      "Epoch 844 took 0.03703474599751644 seconds\n",
      "Epoch 845 took 0.03749173299729591 seconds\n",
      "Epoch 846 took 0.036702682002214715 seconds\n",
      "Epoch 847 took 0.037335785000323085 seconds\n",
      "Epoch 848 took 0.03801841499807779 seconds\n",
      "Epoch 849 took 0.0352976239992131 seconds\n",
      "Epoch 850 took 0.037031332998594735 seconds\n",
      "Epoch 851 took 0.038100400000985246 seconds\n",
      "Epoch 852 took 0.03740971899969736 seconds\n",
      "Epoch 853 took 0.03726702700078022 seconds\n",
      "Epoch 854 took 0.037202106999757234 seconds\n",
      "Epoch 855 took 0.035969548000139184 seconds\n",
      "Epoch 856 took 0.038685764997353544 seconds\n",
      "Epoch 857 took 0.03786718899937114 seconds\n",
      "Epoch 858 took 0.03871240700027556 seconds\n",
      "Epoch 859 took 0.03848706699864124 seconds\n",
      "Epoch 860 took 0.03867417799847317 seconds\n",
      "Epoch 861 took 0.04457551800078363 seconds\n",
      "Epoch 862 took 0.04281017899847939 seconds\n",
      "Epoch 863 took 0.039246506999916164 seconds\n",
      "Epoch 864 took 0.03699787799996557 seconds\n",
      "Epoch 865 took 0.043362645999877714 seconds\n",
      "Epoch 866 took 0.039068508998752804 seconds\n",
      "Epoch 867 took 0.036556880000716774 seconds\n",
      "Epoch 868 took 0.03792220800096402 seconds\n",
      "Epoch 869 took 0.03639765200205147 seconds\n",
      "Epoch 870 took 0.03769421199831413 seconds\n",
      "Epoch 871 took 0.03685285699975793 seconds\n",
      "Epoch 872 took 0.03732287200182327 seconds\n",
      "Epoch 873 took 0.035512686998117715 seconds\n",
      "Epoch 874 took 0.03855144200133509 seconds\n",
      "Epoch 875 took 0.03664571399713168 seconds\n",
      "Epoch 876 took 0.03974880399982794 seconds\n",
      "Epoch 877 took 0.03733931399983703 seconds\n",
      "Epoch 878 took 0.039474756998970406 seconds\n",
      "Epoch 879 took 0.03939682399868616 seconds\n",
      "Epoch 880 took 0.0382605369995872 seconds\n",
      "Epoch 881 took 0.03653808899980504 seconds\n",
      "Epoch 882 took 0.03700611800013576 seconds\n",
      "Epoch 883 took 0.03858205799770076 seconds\n",
      "Epoch 884 took 0.03988298200056306 seconds\n",
      "Epoch 885 took 0.03739573299753829 seconds\n",
      "Epoch 886 took 0.03796852400046191 seconds\n",
      "Epoch 887 took 0.037176294998062076 seconds\n",
      "Epoch 888 took 0.0359699910004565 seconds\n",
      "Epoch 889 took 0.03632597700197948 seconds\n",
      "Epoch 890 took 0.03687269399961224 seconds\n",
      "Epoch 891 took 0.03613583500191453 seconds\n",
      "Epoch 892 took 0.03820466699835379 seconds\n",
      "Epoch 893 took 0.036383929997100495 seconds\n",
      "Epoch 894 took 0.03659195799991721 seconds\n",
      "Epoch 895 took 0.036530355999275343 seconds\n",
      "Epoch 896 took 0.036904159002006054 seconds\n",
      "Epoch 897 took 0.036351997001474956 seconds\n",
      "Epoch 898 took 0.03722327700234018 seconds\n",
      "Epoch 899 took 0.03649695200147107 seconds\n",
      "Epoch 900 took 0.036963012997148326 seconds\n",
      "Epoch 901 took 0.0374938499990094 seconds\n",
      "Epoch 902 took 0.0379439589996764 seconds\n",
      "Epoch 903 took 0.03758266799923149 seconds\n",
      "Epoch 904 took 0.0372109370000544 seconds\n",
      "Epoch 905 took 0.03760007900200435 seconds\n",
      "Epoch 906 took 0.03711576799832983 seconds\n",
      "Epoch 907 took 0.036349611000332516 seconds\n",
      "Epoch 908 took 0.0353450199982035 seconds\n",
      "Epoch 909 took 0.03628723699875991 seconds\n",
      "Epoch 910 took 0.037486757999431575 seconds\n",
      "Epoch 911 took 0.03744334200018784 seconds\n",
      "Epoch 912 took 0.0358423670004413 seconds\n",
      "Epoch 913 took 0.03640984100275091 seconds\n",
      "Epoch 914 took 0.03669257499859668 seconds\n",
      "Epoch 915 took 0.038276096998743014 seconds\n",
      "Epoch 916 took 0.03663748500184738 seconds\n",
      "Epoch 917 took 0.03647617499882472 seconds\n",
      "Epoch 918 took 0.03662968800199451 seconds\n",
      "Epoch 919 took 0.03837350699905073 seconds\n",
      "Epoch 920 took 0.036973677000787575 seconds\n",
      "Epoch 921 took 0.037053767999168485 seconds\n",
      "Epoch 922 took 0.037312825999833876 seconds\n",
      "Epoch 923 took 0.03659069800050929 seconds\n",
      "Epoch 924 took 0.03733641099825036 seconds\n",
      "Epoch 925 took 0.03688646400041762 seconds\n",
      "Epoch 926 took 0.03797413899883395 seconds\n",
      "Epoch 927 took 0.03641227600019192 seconds\n",
      "Epoch 928 took 0.04001312000036705 seconds\n",
      "Epoch 929 took 0.036265506998461206 seconds\n",
      "Epoch 930 took 0.0367301430014777 seconds\n",
      "Epoch 931 took 0.03613828400193597 seconds\n",
      "Epoch 932 took 0.03596150200246484 seconds\n",
      "Epoch 933 took 0.0376799250007025 seconds\n",
      "Epoch 934 took 0.03677523299847962 seconds\n",
      "Epoch 935 took 0.036909260001266375 seconds\n",
      "Epoch 936 took 0.036645173000579234 seconds\n",
      "Epoch 937 took 0.03588738400139846 seconds\n",
      "Epoch 938 took 0.037551285000517964 seconds\n",
      "Epoch 939 took 0.03739748100269935 seconds\n",
      "Epoch 940 took 0.03693045099862502 seconds\n",
      "Epoch 941 took 0.03702120299931266 seconds\n",
      "Epoch 942 took 0.03603676299826475 seconds\n",
      "Epoch 943 took 0.03709029500168981 seconds\n",
      "Epoch 944 took 0.03725917399788159 seconds\n",
      "Epoch 945 took 0.0358398339994892 seconds\n",
      "Epoch 946 took 0.03783259500050917 seconds\n",
      "Epoch 947 took 0.036821645000600256 seconds\n",
      "Epoch 948 took 0.03744459800145705 seconds\n",
      "Epoch 949 took 0.036577082002622774 seconds\n",
      "Epoch 950 took 0.03606602199943154 seconds\n",
      "Epoch 951 took 0.035830879998684395 seconds\n",
      "Epoch 952 took 0.03678991400011 seconds\n",
      "Epoch 953 took 0.03795051199995214 seconds\n",
      "Epoch 954 took 0.03618200300115859 seconds\n",
      "Epoch 955 took 0.03862778699840419 seconds\n",
      "Epoch 956 took 0.03778584099927684 seconds\n",
      "Epoch 957 took 0.03656931799923768 seconds\n",
      "Epoch 958 took 0.037477606998436386 seconds\n",
      "Epoch 959 took 0.03638919100194471 seconds\n",
      "Epoch 960 took 0.03730800400080625 seconds\n",
      "Epoch 961 took 0.03638246199989226 seconds\n",
      "Epoch 962 took 0.03705316999912611 seconds\n",
      "Epoch 963 took 0.03994865999993635 seconds\n",
      "Epoch 964 took 0.037174024000705685 seconds\n",
      "Epoch 965 took 0.03625629999805824 seconds\n",
      "Epoch 966 took 0.036349395999422995 seconds\n",
      "Epoch 967 took 0.03578164899954572 seconds\n",
      "Epoch 968 took 0.03672759500113898 seconds\n",
      "Epoch 969 took 0.037809712997841416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970 took 0.03730275599809829 seconds\n",
      "Epoch 971 took 0.03694468899993808 seconds\n",
      "Epoch 972 took 0.036744297001860105 seconds\n",
      "Epoch 973 took 0.03531972299970221 seconds\n",
      "Epoch 974 took 0.03667389800102683 seconds\n",
      "Epoch 975 took 0.036251442001230316 seconds\n",
      "Epoch 976 took 0.037435214002471184 seconds\n",
      "Epoch 977 took 0.0365858439981821 seconds\n",
      "Epoch 978 took 0.03651563400126179 seconds\n",
      "Epoch 979 took 0.03630466700269608 seconds\n",
      "Epoch 980 took 0.0358691630026442 seconds\n",
      "Epoch 981 took 0.038931044000491966 seconds\n",
      "Epoch 982 took 0.03831699899819796 seconds\n",
      "Epoch 983 took 0.03632655500041437 seconds\n",
      "Epoch 984 took 0.037745883000752656 seconds\n",
      "Epoch 985 took 0.03684803499709233 seconds\n",
      "Epoch 986 took 0.03611324300072738 seconds\n",
      "Epoch 987 took 0.03753048100043088 seconds\n",
      "Epoch 988 took 0.0378951760030759 seconds\n",
      "Epoch 989 took 0.03701084799831733 seconds\n",
      "Epoch 990 took 0.04196375899846316 seconds\n",
      "Epoch 991 took 0.041243862000555964 seconds\n",
      "Epoch 992 took 0.041965272997913416 seconds\n",
      "Epoch 993 took 0.04395632999876398 seconds\n",
      "Epoch 994 took 0.03804348500125343 seconds\n",
      "Epoch 995 took 0.03627861700078938 seconds\n",
      "Epoch 996 took 0.037649458998203045 seconds\n",
      "Epoch 997 took 0.0366170349989261 seconds\n",
      "Epoch 998 took 0.03762603999712155 seconds\n",
      "Epoch 999 took 0.0385240600007819 seconds\n",
      "Training took 40.5326841879978 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XHW9//HXJ5OZTPat6UJTaGlLoWwFSqGyyBXFAiIq\nyCIgcHnc6lUeiuuFq9eF+/MqV694uYKCAiLIJqBWLCCLuEJpqLW0paULpU3pkqZNsy+TfH5/zEmZ\nptNO0mYy6eT9fDzy6Jxzvmfmc3LSvHO+37OYuyMiIrIvOZkuQEREhj+FhYiIpKSwEBGRlBQWIiKS\nksJCRERSUliIiEhKCguRQWBmPzOz/9fPtuvM7L0H+j4iQ0lhISIiKSksREQkJYWFjBhB98+XzGyJ\nmbWY2d1mNsbMnjKzJjN7zszKE9p/0MyWmVmDmb1oZkclLDvBzBYF6z0CRPt81gfMbHGw7t/M7Lj9\nrPlfzGy1mW03s3lmdkgw38zsVjPbamaNZvaamR0TLDvPzJYHtW00sy/u1zdMJIHCQkaai4D3AUcA\nFwBPAf8OVBH///AZADM7AngIuCFYNh/4rZlFzCwC/Bq4H6gAfhm8L8G6JwD3AJ8AKoE7gXlmljeQ\nQs3sPcC3gUuAccBbwMPB4nOAM4PtKA3a1AfL7gY+4e7FwDHACwP5XJFkFBYy0vyfu29x943An4EF\n7v53d28HfgWcELS7FPiduz/r7l3A94B84F3AqUAY+IG7d7n7Y8DChM+YC9zp7gvcvdvd7wM6gvUG\n4grgHndf5O4dwE3AbDObCHQBxcCRgLn76+6+KVivC5huZiXuvsPdFw3wc0X2oLCQkWZLwuu2JNNF\nwetDiP8lD4C79wAbgPHBso2++10430p4fRjwhaALqsHMGoAJwXoD0beGZuJHD+Pd/QXgh8DtwFYz\nu8vMSoKmFwHnAW+Z2R/NbPYAP1dkDwoLkeTeJv5LH4iPERD/hb8R2ASMD+b1OjTh9QbgW+5elvBV\n4O4PHWANhcS7tTYCuPtt7n4SMJ14d9SXgvkL3f1CYDTx7rJHB/i5IntQWIgk9yhwvpmdbWZh4AvE\nu5L+BrwExIDPmFnYzD4CzEpY9yfAJ83slGAgutDMzjez4gHW8BBwrZnNCMY7/ot4t9k6Mzs5eP8w\n0AK0Az3BmMoVZlYadJ81Aj0H8H0QARQWIkm5+0rgSuD/gG3EB8MvcPdOd+8EPgJcA2wnPr7xRMK6\nNcC/EO8m2gGsDtoOtIbngP8AHid+NDMZuCxYXEI8lHYQ76qqB74bLLsKWGdmjcAniY99iBwQ08OP\nREQkFR1ZiIhISgoLERFJSWEhIiIpKSxERCSl3EwXMFhGjRrlEydOzHQZIiIHlVdffXWbu1elapc1\nYTFx4kRqamoyXYaIyEHFzN5K3UrdUCIi0g8KCxERSUlhISIiKWXNmEUyXV1d1NbW0t7enulS0i4a\njVJdXU04HM50KSKShbI6LGpraykuLmbixInsfoPQ7OLu1NfXU1tby6RJkzJdjohkoazuhmpvb6ey\nsjKrgwLAzKisrBwRR1AikhlZHRZA1gdFr5GynSKSGVkfFql09zibG9tp7YxluhQRkWFrxIeFu7O1\nsZ3Wzu60vH9DQwN33HHHgNc777zzaGhoSENFIiIDl9awMLM5ZrbSzFab2Y1Jlp9pZovMLGZmFydZ\nXmJmtWb2w/TVGP83XY/12FtYxGL7PpKZP38+ZWVl6SlKRGSA0nY2lJmFiD9M/n1ALbDQzOa5+/KE\nZuuJP0Hsi3t5m/8E/pSuGgGMeFqk6yFQN954I2vWrGHGjBmEw2Gi0Sjl5eWsWLGCN954gw996ENs\n2LCB9vZ2PvvZzzJ37lzgnduXNDc3c+6553L66afzt7/9jfHjx/Ob3/yG/Pz8tNQrIpJMOk+dnQWs\ndve1AGb2MHAhsCss3H1dsGyPZwSb2UnAGOBpYOaBFvPN3y5j+duNSZe1dMSI5OYQDg3sQGv6ISV8\n/YKj99nmO9/5DkuXLmXx4sW8+OKLnH/++SxdunTXKa733HMPFRUVtLW1cfLJJ3PRRRdRWVm523us\nWrWKhx56iJ/85CdccsklPP7441x55ZUDqlVE5ECksxtqPLAhYbo2mJeSmeUA/8Pejzh62801sxoz\nq6mrq9vvQgGG6uGys2bN2u1aiNtuu43jjz+eU089lQ0bNrBq1ao91pk0aRIzZswA4KSTTmLdunVD\nVK2ISNxwvSjvU8B8d6/d1ymh7n4XcBfAzJkz9/n7fl9HAEs37qSyMMK4svR37RQWFu56/eKLL/Lc\nc8/x0ksvUVBQwFlnnZX0Wom8vLxdr0OhEG1tbWmvU0QkUTrDYiMwIWG6OpjXH7OBM8zsU0AREDGz\nZnffY5B8MJil78iiuLiYpqampMt27txJeXk5BQUFrFixgpdffjlNVYiIHJh0hsVCYKqZTSIeEpcB\nH+vPiu5+Re9rM7sGmJmuoID4IHdPmga4KysrOe200zjmmGPIz89nzJgxu5bNmTOHH//4xxx11FFM\nmzaNU089NS01iIgcqLSFhbvHzOx64BkgBNzj7svM7Gagxt3nmdnJwK+AcuACM/umu+97xDgNzNJ3\n6izAgw8+mHR+Xl4eTz31VNJlveMSo0aNYunSpbvmf/GL+xzGERFJi7SOWbj7fGB+n3lfS3i9kHj3\n1L7e42fAz9JQ3i45aeyGEhHJBiP+Cm6Id0Ol6zoLEZFskPVh0Z8QSHc31FBQ2IlIOmV1WESjUerr\n61P+IjVL3wD3UOh9nkU0Gs10KSKSpYbrdRaDorq6mtraWlJdsFfX1AFAx7a8fbYbznqflCcikg5Z\nHRbhcLhfT4675d5X2N7SybzrZwxBVSIiB5+s7obqr2huiPau9NyiXEQkGygsgGg4hzaFhYjIXiks\ngPxIiPauPW58KyIiAYUFkKduKBGRfVJY0HtkobAQEdkbhQXxAe6ubifWra4oEZFkFBZAQSQEoEFu\nEZG9UFgABXnxsGjpUFiIiCSjsACK8uLXJrZ0xjJciYjI8KSwAAoi8bBo1ZGFiEhSCgugMOiGau7Q\nkYWISDIKC6Cw98hC3VAiIkkpLNCRhYhIKgoLoDCv98hCYxYiIskoLHhngLtFRxYiIkkpLIDCiK6z\nEBHZF4UFkBvKIS83RwPcIiJ7kdawMLM5ZrbSzFab2Y1Jlp9pZovMLGZmFyfMn2FmL5nZMjNbYmaX\nprNOiI9baIBbRCS5tIWFmYWA24FzgenA5WY2vU+z9cA1wIN95rcCH3f3o4E5wA/MrCxdtUL8jCgN\ncIuIJJfOZ3DPAla7+1oAM3sYuBBY3tvA3dcFy3a73au7v5Hw+m0z2wpUAQ3pKrYwoiMLEZG9SWc3\n1HhgQ8J0bTBvQMxsFhAB1iRZNtfMasyspq6ubr8LhXg3lMYsRESSG9YD3GY2DrgfuNbd93jYhLvf\n5e4z3X1mVVXVAX1WQSSks6FERPYinWGxEZiQMF0dzOsXMysBfgd8xd1fHuTa9lAYydV1FiIie5HO\nsFgITDWzSWYWAS4D5vVnxaD9r4Cfu/tjaaxxl3g3lI4sRESSSVtYuHsMuB54BngdeNTdl5nZzWb2\nQQAzO9nMaoGPAnea2bJg9UuAM4FrzGxx8DUjXbVC/GwoDXCLiCSXzrOhcPf5wPw+876W8Hoh8e6p\nvus9ADyQztr6KomGaWrvoqfHycmxofxoEZFhb1gPcA+l0vwwPQ7NOiNKRGQPCotAaX4YgJ2tXRmu\nRERk+FFYBEp6w6JNYSEi0pfCItB7ZNGosBAR2YPCIlCqIwsRkb1SWARKCxQWIiJ7o7AI6MhCRGTv\nFBaBwkiIUI4pLEREklBYBMyM0vywwkJEJAmFRQKFhYhIcgqLBCUKCxGRpBQWCUrzw7rOQkQkCYVF\nAnVDiYgkp7BIUJqfq7AQEUlCYZGgND9MY3sMd890KSIiw4rCIkFpfpjuHtdDkERE+lBYJNBV3CIi\nySksEvSGRYOeaSEishuFRYIS3aZcRCQphUUCdUOJiCSnsEigsBARSU5hkUBhISKSXFrDwszmmNlK\nM1ttZjcmWX6mmS0ys5iZXdxn2dVmtir4ujqddfYqysvVbcpFRJJIW1iYWQi4HTgXmA5cbmbT+zRb\nD1wDPNhn3Qrg68ApwCzg62ZWnq5aEz6Xkqiu4hYR6SudRxazgNXuvtbdO4GHgQsTG7j7OndfAvT0\nWff9wLPuvt3ddwDPAnPSWOsuuj+UiMie0hkW44ENCdO1wbxBW9fM5ppZjZnV1NXV7XehiRQWIiJ7\nOqgHuN39Lnef6e4zq6qqBuU9SwsiCgsRkT7SGRYbgQkJ09XBvHSve0AqCsLsaO0cio8SETlopDMs\nFgJTzWySmUWAy4B5/Vz3GeAcMysPBrbPCealXXlhhB0tOrIQEUmUtrBw9xhwPfFf8q8Dj7r7MjO7\n2cw+CGBmJ5tZLfBR4E4zWxasux34T+KBsxC4OZiXdhUFEZo7YnTEuofi40REDgq56Xxzd58PzO8z\n72sJrxcS72JKtu49wD3prC+Z8sIIEL+Z4JiS0FB/vIjIsHRQD3CnQ0UQFttbNG4hItJLYdFHeUE8\nLDTILSLyDoVFH71HFhrkFhF5h8Kij/LC+M0Et+vIQkRkF4VFH7u6oTRmISKyi8Kij3Aoh+Jorga4\nRUQSKCySKC+IaIBbRCSBwiKJ8sKIjixERBIoLJLQ/aFERHansEhC94cSEdmdwiKJCo1ZiIjsRmGR\nRHlhhNbObtq7dDNBERFQWCS16ypuHV2IiAAKi6R6L8zTGVEiInEKiyR051kRkd0pLJJQWIiI7E5h\nkURVUR4A25oVFiIioLBIqiQ/l3DI2NbckelSRESGBYVFEmZGZWEe9QoLERFAYbFXlUURdUOJiAQU\nFnsxqihP3VAiIoF+hYWZfdbMSizubjNbZGbnpLu4TKosilCvIwsREaD/Rxb/7O6NwDlAOXAV8J1U\nK5nZHDNbaWarzezGJMvzzOyRYPkCM5sYzA+b2X1m9pqZvW5mN/V7iwZJVVEedc0duPtQf7SIyLDT\n37Cw4N/zgPvdfVnCvOQrmIWA24FzgenA5WY2vU+z64Ad7j4FuBW4JZj/USDP3Y8FTgI+0RskQ6Wy\nKEJnrIfmjthQfqyIyLDU37B41cx+TzwsnjGzYqAnxTqzgNXuvtbdO4GHgQv7tLkQuC94/RhwtpkZ\n4EChmeUC+UAn0NjPWgfFKF1rISKyS3/D4jrgRuBkd28FwsC1KdYZD2xImK4N5iVt4+4xYCdQSTw4\nWoBNwHrge+6+vZ+1DoresNDpsyIi/Q+L2cBKd28wsyuBrxL/xZ4us4Bu4BBgEvAFMzu8byMzm2tm\nNWZWU1dXN6gFVBbFb/mhM6JERPofFj8CWs3seOALwBrg5ynW2QhMSJiuDuYlbRN0OZUC9cDHgKfd\nvcvdtwJ/BWb2/QB3v8vdZ7r7zKqqqn5uSv/olh8iIu/ob1jEPH5a0IXAD939dqA4xToLgalmNsnM\nIsBlwLw+beYBVwevLwZeCD5nPfAeADMrBE4FVvSz1kFRHtxMsK5JRxYiIrn9bNcUnL56FXCGmeUQ\nH7fYK3ePmdn1wDNACLjH3ZeZ2c1AjbvPA+4G7jez1cB24oEC8bOo7jWz3rOu7nX3JQPduAMRDuUw\nqiiPrU3tQ/mxIiLDUn/D4lLiXUP/7O6bzexQ4LupVnL3+cD8PvO+lvC6nfhpsn3Xa042f6iNK42y\naafCQkSkX91Q7r4Z+AVQamYfANrdPdWYxUFvbGmUzQoLEZF+3+7jEuAV4n/tXwIsMLOL01nYcKAj\nCxGRuP52Q32F+DUWWwHMrAp4jvj1EFlrbGmUnW1dtHbGKIj091slIpJ9+ns2VE5vUATqB7DuQWtc\naRRAXVEiMuL198/lp83sGeChYPpS+gxcZ6OxJflAPCwOryrKcDUiIpnTr7Bw9y+Z2UXAacGsu9z9\nV+kra3joPbLQuIWIjHT97oh398eBx9NYy7AztrcbqlFhISIj2z7DwsyaiN8Bdo9FgLt7SVqqGiai\n4RDlBWE27WzLdCkiIhm1z7Bw91S39Mh6Y0vzNcAtIiNe1p/RdKB0rYWIiMIiJV3FLSKisEhpXEmU\n+pZO2ru6M12KiEjGKCxS6D0jamujblUuIiOXwiKFcaXxC/N0RpSIjGQKixR0rYWIiMIipbG6iltE\nRGGRSlFeLsXRXJ0RJSIjmsKiH+LXWmjMQkRGLoVFP+gqbhEZ6RQW/XCIruIWkRFOYdEPY0uj1DV3\n0NXdk+lSREQyQmHRD+NKo7jD1iZdmCciI5PCoh/GBhfmvd2gQW4RGZnSGhZmNsfMVprZajO7Mcny\nPDN7JFi+wMwmJiw7zsxeMrNlZvaamUXTWeu+HFZRAMC6bS2ZKkFEJKPSFhZmFgJuB84FpgOXm9n0\nPs2uA3a4+xTgVuCWYN1c4AHgk+5+NHAW0JWuWlOpLs8nEsphTZ3CQkRGpnQeWcwCVrv7WnfvBB4G\nLuzT5kLgvuD1Y8DZZmbAOcASd/8HgLvXu3vGbvuaG8ph4qgC1tQ1Z6oEEZGMSmdYjAc2JEzXBvOS\ntnH3GLATqASOANzMnjGzRWb25WQfYGZzzazGzGrq6uoGfQMSTa4qUliIyIg1XAe4c4HTgSuCfz9s\nZmf3beTud7n7THefWVVVldaCJlcVsb6+VafPisiIlM6w2AhMSJiuDuYlbROMU5QC9cSPQv7k7tvc\nvRWYD5yYxlpTOryqkFiP81Z9aybLEBHJiHSGxUJgqplNMrMIcBkwr0+becDVweuLgRfc3YFngGPN\nrCAIkXcDy9NYa0qTq4oA1BUlIiNSbrre2N1jZnY98V/8IeAed19mZjcDNe4+D7gbuN/MVgPbiQcK\n7r7DzL5PPHAcmO/uv0tXrf1xeFUhoLAQkZEpbWEB4O7ziXchJc77WsLrduCje1n3AeKnzw4LxdEw\nY0ryWLNVp8+KyMgzXAe4hyWdESUiI5XCYgAOrypkbV0z8WEVEZGRQ2ExAFOqimhsj7GlUTcUFJGR\nRWExAMdWlwHwj9qGDFciIjK0FBYDcPQhJeTmGIs3KCxEZGRRWAxANBziqHElLF6vsBCRkUVhMUAz\nJpSxpLaBmG77ISIjiMJigGZPrqSls5u/qytKREYQhcUAnTZlFKEc48WVWzNdiojIkFFYDFBpfpgT\nDy3jxZXpvSW6iMhworDYD2dNG82ytxvZ2tie6VJERIaEwmI/nDN9DAC/Xtz3jusiItlJYbEfpo4p\nZtbECn6xYD09Pbr1h4hkP4XFfrpq9mG8Vd/Kb5e8nelSRETSTmGxn84/dhzTx5XwnadWaOxCRLKe\nwmI/5eQY//WRY2lo7eKrv16a6XJERNJKYXEAZkwo41/OmMTvl2/h0YUbMl2OiEjaKCwO0GfOnsqs\niRXc+MQSnl66OdPliIikhcLiAOWGcrjr4ydxaEUB1z+4iJfX1me6JBGRQaewGARlBREe+cRsDqss\nYO7Pa1i9tSnTJYmIDCqFxSAZUxLlZ9fOIpIb4sqfvsKqLQoMEckeCotBNKGigDuvOpHG9i6uu6+G\nHS2dmS5JRGRQpDUszGyOma00s9VmdmOS5Xlm9kiwfIGZTeyz/FAzazazL6azzsF00mEV3H/dKWxu\nbOeae1+hqb0r0yWJiBywtIWFmYWA24FzgenA5WY2vU+z64Ad7j4FuBW4pc/y7wNPpavGdDnpsHLu\n+NiJLHu7kU8+8CpdelCSiBzk0nlkMQtY7e5r3b0TeBi4sE+bC4H7gtePAWebmQGY2YeAN4Flaawx\nbd47fQy3XHQcf11dz3X31dDW2Z3pkkRE9ls6w2I8kHilWm0wL2kbd48BO4FKMysC/g345r4+wMzm\nmlmNmdXU1Q2/50tcdFI137hgOn96o44vPfYP3XRQRA5aw3WA+xvAre7evK9G7n6Xu89095lVVVVD\nU9kAXXPaJL54zhE8uWQTV/x0AR0xHWGIyMEnnWGxEZiQMF0dzEvaxsxygVKgHjgF+G8zWwfcAPy7\nmV2fxlrT6tP/NIVvffgYXlpbz7SvPs1rtTszXZKIyICkMywWAlPNbJKZRYDLgHl92swDrg5eXwy8\n4HFnuPtEd58I/AD4L3f/YRprTSsz44pTDuOzZ08F4IIf/oVf1uheUiJy8EhbWARjENcDzwCvA4+6\n+zIzu9nMPhg0u5v4GMVq4PPAHqfXZpPPve8IvjxnGgBfemwJ35i3TOMYInJQMPfs+GU1c+ZMr6mp\nyXQZ/fLX1du44qcLAPj47MP4+gVHE8qxDFclIiORmb3q7jNTtRuuA9xZ7bQpo3j95jmcMXUUP3/p\nLa659xUaWnW1t4gMXwqLDMmPhLj/ulO45aJjeXltPXN+8GdeXLk102WJiCSlsMiwS08+lIfnnsq2\n5g4+98hifv33jWRL16CIZA+FxTBw0mEVPH3DGURyc7jhkcXMvf9VWjtjmS5LRGQXhcUwMWV0Mc9/\n4SzOPKKKZ5dv4bz//bPuKSUiw4bCYhgpysvlvmtP5rxjx7KuvpXL7nqZrY3tmS5LRERhMdyYGXdc\ncRI/uHQGy99u5F3feYFHF25gZ6tudS4imaOwGKY+dMJ4nvjUu5hQUcCXH1/CWd/7g+4rJSIZo7AY\nxo4aV8IvPzmbKaOL2NHaxQX/9xc271S3lIgMPYXFMDeqKI9nP3cm37/keDbuaOO93/8jTy55O9Nl\nicgIo7A4CJgZHzmxmsf+Nd4tdf2Df+eKn76sbikRGTIKi4PIUeNKeOJf38UlM6v56+p6ZnzzWR54\n+a1MlyUiI4DC4iCTHwnx3xcfz91Xz6Stq5uv/nop3/rdcj22VUTSSmFxkDr7qDGs+ta5fPiE8fzk\nz29y1Nee5lE9I0NE0kRhcRALh3K49dIZ3HnVSYwuzuPfHl/Ctfe+wqL1O+jWczJEZBDlZroAOXDv\nP3os75pcyY//uIa7/rSWP6ysY9bECm67/ATGlkYzXZ6IZAEdWWSJ4miYL73/SP7wxbOYMrqIV9Zt\n5+z/eZEfvbiGuqaOTJcnIgc5hUWWqS4v4LnPv5vfXn8608YWc8vTK3j3d//APX95M9OlichBTI9V\nzXK/WbyRGx9/jbaubmZMKOOUwyv43HuPIBoOZbo0ERkG+vtYVY1ZZLkLZ4xnzjFj+fGLa7n1uTdY\nvKGBZRsb+fZHjmVCRUGmyxORg4SOLEaQuqYObnt+FU8sqqXbnQ8cdwhzzzycI8YUZ7o0EcmQ/h5Z\nKCxGoLcb2vjW/NeZ/9omcnOMOceM49rTJnLChDLMLNPlicgQ6m9YpHWA28zmmNlKM1ttZjcmWZ5n\nZo8EyxeY2cRg/vvM7FUzey349z3prHOkOaQsn9s/diILbjqb848dx2//8TYfueNvnPrt53l04QY9\nA1xE9pC2IwszCwFvAO8DaoGFwOXuvjyhzaeA49z9k2Z2GfBhd7/UzE4Atrj722Z2DPCMu4/f1+fp\nyGL/vfLmdq786QI6Ex7jWlWcx6OfmM3EygIdbYhksYx3Q5nZbOAb7v7+YPomAHf/dkKbZ4I2L5lZ\nLrAZqPKEoiz+m6oeGOfue71gQGFx4Nq7urnjxTXc9vyq3ebfeO6RHDe+lFMPryQnR8Ehkk2Gw9lQ\n44HEmxXVAqfsrY27x8xsJ1AJbEtocxGwaF9BIYMjGg7x+fcdwefeO5Xlmxp57NVa7v3rOr7z1AoA\n8nJzuPLUw2jr6uYr5x1FYZ5OphMZKYb1/3YzOxq4BThnL8vnAnMBDj300CGsLLuZGUcfUsrRh5Ty\nlfOO4oUVW/nSY0vY2dbF3cHFfQ8uWM+Jh5YxujjK6VNHceTYYiZXFVGaH9bRh0gWSmdYbAQmJExX\nB/OStakNuqFKiXc5YWbVwK+Aj7v7mmQf4O53AXdBvBtqUKsXAHJDOZxz9FjOOXos7s767a088PJb\n/G7JJhatbwDg6WWbd7WfMaGMaDiHnh44/7hxnHJ4BdPGFGNmuLvGP0QOUukcs8glPsB9NvFQWAh8\nzN2XJbT5NHBswgD3R9z9EjMrA/4IfNPdn+jP52nMYuh19zhr65qpeWsH//nkclr38UyN0cV5NHfE\nmDGhjE072zm0ooBwyDhr2miaO2Ks3NxEaX6YrU3tXHnKYVSXF9DY3oUZFOXl0tDaxbHjS3cdtbR3\ndZOXmzOg8Il19xDrcaLhENtbOqkojCRt5+68tKae2ZMrFW6S9TI+wB0UcR7wAyAE3OPu3zKzm4Ea\nd59nZlHgfuAEYDtwmbuvNbOvAjcBiSOt57j71r19lsJieOiM9dDU3sWytxtp6+rmlzW1TKjIZ0tj\nO69vamJnWxfbWzr3671HF+dRURhhY0MbTe0xAPLDIUaX5BEJ5TBldBEl0TCOE+tx2jq72bSznclV\nRRRHc/nZ39aRY8QfUftq7a73/dRZkznx0HJWbmmiu8dZUtvAc69v5ZDSKJ8/ZxrPv76FS0+ewMTK\nQtZvb+WFFVs54dAyCiK5vFXfwqotzXzyrMm0dMQojuYypiRKfUsnd/xhNR86YTzTxhYT63ZyDJra\nY+SGjNodbYwuzmPD9jZmT64klGPUrNtOrMd55c3tfOLdh/P6piYmVxVSHA0D0NPjOJBj0BHr4c+r\ntjFrYgWlBeE99sEbW5o4ZnwpAB2xbtZta+XwqkLCoT3Plt/R0kmPO5VFeXssSzwa3NHSSVlBeNf0\nhu2t5EdCjEqyXl9/X7+D46rLCOUYbze0EcnN6dd6kn7DIiyGksLi4NHV3UN3j7OxoY365k5aOmO0\ndnTjxP+iP6yygI6uHrY1d9DS2U1DaxevvFnPUeNKAGjpjLF6azPtXT2MLs6ju8dpaOuiMBIiN5RD\nV6yHpo5YhrdyYIrzcneruTASoiXhSG1UUR7NHV3x0MkxOmPvnOZ8WGUBITNiPfFuwl7HjC9h6cbG\nPT6rIBLirGlVbGvuZMP2VjbtbAfij+2dNKqAFZua2NzYzpFji1m0voFpY4pxnDe2NFMQCXH0ISV0\nxnr4R+1OAN41uZKCSIijxpWwtbGD1zbupK65g6mji5hzzFh+v2wLf1m9jcrCCJ/+pync/GT87PlP\nvPtwygtE3K/MAAAJzUlEQVQibGvq4Kd/eZOKwghXnHIoY0qitHTECOXEQ7UkP0x1WT5v1rfwxKJa\njhhTzAeOG8e25k6++8xKzj9uHFOqinhhxVYuOnE8lUV5bGvuoLEtxqSqQp5euontLZ2cNnkUpQVh\nnl2+hbzcHHJzcigvjDC5qpBDKwr45au1XHHKoZQVRHirvoU/vbGN4mgueeEc5hw9lqb2GB+/5xVO\nOqycH115IttbOvnr6nomVhbQ1B6jujyf46rLaO2MUdfUQU6Oce9f32TjjjZuvvAYVm9tZuG67Vx7\n2iQWb2jg6aWbOfOIUXzguEPoiHXzwoqtlOVH6Orpobk9xpFji3fdkmdNXTOPvVrL9HElXDhjfPAz\n38mY4igbG9qoLIpQENm/UQWFhYxo7k57Vw/NHTEK80J0xRzLgZ2tXbhDV08P7k5RXpjtLZ20x7pp\nao9x+KhCVmxuojiaS3ePs72lkzElUZZu3EkkN4f2rm6qywvYvLONTY3tNLbFKCsIEzJjbGmUDTta\nycsNUZQXYl19K9uaOpg0qhAzIxrO4ffLtvBPR1axYO12CvNyeX1TI+8+ooqu7h5WbW1m+rgSNja0\nURAJsWlnO+1d3Zw8sYL6lk62NLZTEAkRDYfo7nH+vGob+eEQx4wvoaWjm5wceGNzM8XRXOpbOplc\nVQjAmrqWPb4/FYURqsvz2bijjfrgSC8/HCKUYzRnMGjNIEt+JfVbNJxDe1dP0mX9/X5MG1PM0zec\nsV/dpsPh1FmRjDEz8iMh8iPB3XWD4YmSaHiPtn0fEJXsBouzJlUMSl03vPeIQXmfoRTr7iG3T/dV\nV3cPITM6u3uIhkM0tneRY0Z3jxMJ5dAcHBl0dffQ1d1DcTRMZ6yH+paO+FiRx58n39bVzY6WLsaV\nRYmEcjCDbc3x8GpujxHKiZ/Svb6+FSd+sWhjWxcNrV0UREJUFuWxubGdorxc3J3O7h5aO7rpdqcs\nP8zWpg563CnND9PS0c32lg6qywvoiMX/kHB3wqEccnKMpvYuDKMwL0RZQYTNO9vofeBkSTSMGby5\nrYXc4Miux8Fxenqc8sIIKzc3UV4YoSgvN/49aetiQkUBbZ0xepxdR4Qbd7RRu6OV6vICVm1torq8\ngENKo7y2cSdmMK40n7cb2qguj/8cdnZ3s6Wxg9L8MPnhEB2xbjpjPXQ7FOWFAOP0KaPSPr6msBCR\nfeobFMCusY9oTjyM+4bwrpDuo6p493GK4miY0cW7h/X4svw91uv9xZnMtLG6EeZQ0MOPREQkJYWF\niIikpLAQEZGUFBYiIpKSwkJERFJSWIiISEoKCxERSUlhISIiKWXN7T7MrA546wDeYhS7P3RpJNA2\nZ7+Rtr2gbR6ow9y9KlWjrAmLA2VmNf25P0o20TZnv5G2vaBtThd1Q4mISEoKCxERSUlh8Y67Ml1A\nBmibs99I217QNqeFxixERCQlHVmIiEhKCgsREUlpxIeFmc0xs5VmttrMbsx0PYPFzCaY2R/MbLmZ\nLTOzzwbzK8zsWTNbFfxbHsw3M7st+D4sMbMTM7sF+8/MQmb2dzN7MpieZGYLgm17xMwiwfy8YHp1\nsHxiJuveX2ZWZmaPmdkKM3vdzGZn+342s88FP9dLzewhM4tm2342s3vMbKuZLU2YN+D9amZXB+1X\nmdnV+1vPiA4LMwsBtwPnAtOBy81semarGjQx4AvuPh04Ffh0sG03As+7+1Tg+WAa4t+DqcHXXOBH\nQ1/yoPks8HrC9C3Are4+BdgBXBfMvw7YEcy/NWh3MPpf4Gl3PxI4nvi2Z+1+NrPxwGeAme5+DBAC\nLiP79vPPgDl95g1ov5pZBfB14BRgFvD13oAZMHcfsV/AbOCZhOmbgJsyXVeatvU3wPuAlcC4YN44\nYGXw+k7g8oT2u9odTF9AdfCf6D3Ak4ARv7I1t+8+B54BZgevc4N2lultGOD2lgJv9q07m/czMB7Y\nAFQE++1J4P3ZuJ+BicDS/d2vwOXAnQnzd2s3kK8RfWTBOz90vWqDeVklOOw+AVgAjHH3TcGizcCY\n4HW2fC9+AHwZ6AmmK4EGd48F04nbtWubg+U7g/YHk0lAHXBv0PX2UzMrJIv3s7tvBL4HrAc2Ed9v\nr5Ld+7nXQPfroO3vkR4WWc/MioDHgRvcvTFxmcf/1Miac6fN7APAVnd/NdO1DKFc4ETgR+5+AtDC\nO10TQFbu53LgQuJBeQhQyJ7dNVlvqPfrSA+LjcCEhOnqYF5WMLMw8aD4hbs/EczeYmbjguXjgK3B\n/Gz4XpwGfNDM1gEPE++K+l+gzMxygzaJ27Vrm4PlpUD9UBY8CGqBWndfEEw/Rjw8snk/vxd4093r\n3L0LeIL4vs/m/dxroPt10Pb3SA+LhcDU4CyKCPFBsnkZrmlQmJkBdwOvu/v3ExbNA3rPiLia+FhG\n7/yPB2dVnArsTDjcPSi4+03uXu3uE4nvyxfc/QrgD8DFQbO+29z7vbg4aH9Q/QXu7puBDWY2LZh1\nNrCcLN7PxLufTjWzguDnvHebs3Y/Jxjofn0GOMfMyoMjsnOCeQOX6QGcTH8B5wFvAGuAr2S6nkHc\nrtOJH6IuARYHX+cR76t9HlgFPAdUBO2N+Jlha4DXiJ9pkvHtOIDtPwt4Mnh9OPAKsBr4JZAXzI8G\n06uD5Ydnuu793NYZQE2wr38NlGf7fga+CawAlgL3A3nZtp+Bh4iPyXQRP4K8bn/2K/DPwbavBq7d\n33p0uw8REUlppHdDiYhIPygsREQkJYWFiIikpLAQEZGUFBYiIpKSwkJkGDCzs3rvkisyHCksREQk\nJYWFyACY2ZVm9oqZLTazO4NnZzSb2a3B8xWeN7OqoO0MM3s5eL7ArxKePTDFzJ4zs3+Y2SIzmxy8\nfVHCcyl+EVydLDIsKCxE+snMjgIuBU5z9xlAN3AF8RvZ1bj70cAfiT8/AODnwL+5+3HEr6rtnf8L\n4HZ3Px54F/GrdCF+Z+AbiD9b5XDi9zsSGRZyUzcRkcDZwEnAwuCP/nziN3LrAR4J2jwAPGFmpUCZ\nu/8xmH8f8EszKwbGu/uvANy9HSB4v1fcvTaYXkz8WQZ/Sf9miaSmsBDpPwPuc/ebdptp9h992u3v\nPXQ6El53o/+fMoyoG0qk/54HLjaz0bDreciHEf9/1Hu3048Bf3H3ncAOMzsjmH8V8Ed3bwJqzexD\nwXvkmVnBkG6FyH7QXy4i/eTuy83sq8DvzSyH+N1AP038gUOzgmVbiY9rQPwW0j8OwmAtcG0w/yrg\nTjO7OXiPjw7hZojsF911VuQAmVmzuxdlug6RdFI3lIiIpKQjCxERSUlHFiIikpLCQkREUlJYiIhI\nSgoLERFJSWEhIiIp/X8/vh66/oo7gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ef06ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run your model!\n",
    "epochtimer = EpochTimer()\n",
    "epochs = 1000\n",
    "hist = model.fit(X_train, y_train, epochs=epochs, batch_size=50, verbose=0, callbacks=[epochtimer])\n",
    "show_history_graph(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5  Checking model performance\n",
    "\n",
    "With your model fit we can now make predictions on both our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions for training\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we compute training and testing errors using our trained model - you should be able to achieve at least\n",
    "\n",
    "*training_error* < 0.02\n",
    "\n",
    "and \n",
    "\n",
    "*testing_error* < 0.02\n",
    "\n",
    "with your fully trained model.  \n",
    "\n",
    "If either or both of your accuracies are larger than 0.02 re-train your model - increasing the number of epochs you take (a maximum of around 1,000 should do the job) and/or adjusting your batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.0160045073452\n",
      "testing error = 0.0139844171963\n"
     ]
    }
   ],
   "source": [
    "# print out training and testing errors\n",
    "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('training error = ' + str(training_error))\n",
    "\n",
    "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('testing error = ' + str(testing_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activating the next cell plots the original data, as well as both predictions on the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAEKCAYAAABkC+0BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB8d9swAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b4bb470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot everything - the original series as well as predictions on training and testing sets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot original series\n",
    "plt.plot(dataset,color = 'k')\n",
    "\n",
    "# plot training set prediction\n",
    "split_pt = train_test_split + window_size \n",
    "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
    "\n",
    "# plot testing set prediction\n",
    "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
    "\n",
    "# pretty up graph\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('(normalized) price of Apple stock')\n",
    "plt.legend(['original series','training fit','testing fit'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** you can try out any time series for this exercise!  If you would like to try another see e.g., [this site containing thousands of time series](https://datamarket.com/data/list/?q=provider%3Atsdl) and pick another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Create a sequence generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  Getting started\n",
    "\n",
    "In this project you will implement a popular Recurrent Neural Network (RNN) architecture to create an English language sequence generator capable of building semi-coherent English sentences from scratch by building them up character-by-character.  This will require a substantial amount amount of parameter tuning on a large training corpus (at least 100,000 characters long).  In particular for this project we will be using a complete version of Sir Arthur Conan Doyle's classic book The Adventures of Sherlock Holmes.\n",
    "\n",
    "How can we train a machine learning model to generate text automatically, character-by-character?  *By showing the model many training examples so it can learn a pattern between input and output.*  With this type of text generation each input is a string of valid characters like this one\n",
    "\n",
    "*dogs are grea*\n",
    "\n",
    "whlie the corresponding output is the next character in the sentence - which here is 't' (since the complete sentence is 'dogs are great').  We need to show a model many such examples in order for it to make reasonable predictions.\n",
    "\n",
    "**Fun note:** For those interested in how text generation is being used check out some of the following fun resources:\n",
    "\n",
    "- [Generate wacky sentences](http://www.cs.toronto.edu/~ilya/rnn.html) with this academic RNN text generator\n",
    "\n",
    "- Various twitter bots that tweet automatically generated text like[this one](http://tweet-generator-alex.herokuapp.com/).\n",
    "\n",
    "- the [NanoGenMo](https://github.com/NaNoGenMo/2016) annual contest to automatically produce a 50,000+ novel automatically\n",
    "\n",
    "- [Robot Shakespeare](https://github.com/genekogan/RobotShakespeare) a text generator that automatically produces Shakespear-esk sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Preprocessing a text dataset\n",
    "\n",
    "Our first task is to get a large text corpus for use in training, and on it we perform a several light pre-processing tasks.  The default corpus we will use is the classic book Sherlock Holmes, but you can use a variety of others as well - so long as they are fairly large (around 100,000 characters or more).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our original text has 581864 characters\n"
     ]
    }
   ],
   "source": [
    "# read in the text, transforming everything to lower case\n",
    "text = open('datasets/holmes.txt').read().lower()\n",
    "print('our original text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets examine a bit of the raw text.  Because we are interested in creating sentences of English words automatically by building up each word character-by-character, we only want to train on valid English words.  In other words - we need to remove all of the other characters that are not part of English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffproject gutenberg's the adventures of sherlock holmes, by arthur conan doyle\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.net\\n\\n\\ntitle: the adventures of sherlock holmes\\n\\nauthor: arthur conan doyle\\n\\nposting date: april 18, 2011 [ebook #1661]\\nfirst posted: november 29, 2002\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook the adventures of sherlock holmes ***\\n\\n\\n\\n\\nproduced by an anonymous project gutenberg volunteer and jose menendez\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nthe adventures of sherlock holmes\\n\\nby\\n\\nsir arthur conan doyle\\n\\n\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a dist\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 1000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - there's a lot of junk here (i.e., weird uncommon character combinations - as this first character chunk contains the title and author page, as well as table of contents)!  To keep things simple, we want to train our RNN on a large chunk of more typical English sentences - we don't want it to start thinking non-english words or strange characters are valid! - so lets clean up the data a bit.\n",
    "\n",
    "First, since the dataset is so large and the first few hundred characters contain a lot of junk, lets cut it out.  Lets also find-and-replace those newline tags with empty spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find and replace '\\n' and '\\r' symbols - replacing them \n",
    "text = text[1302:]\n",
    "text = text.replace('\\n',' ')    # replacing '\\n' with '' simply removes the sequence\n",
    "text = text.replace('\\r',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the first 1000 characters of our text looks now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer--excellent for drawing the veil from men's motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene ad\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 1000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_3'></a>\n",
    "\n",
    "#### TODO: finish cleaning the text\n",
    "\n",
    "Lets make sure we haven't left any other atypical characters (commas, periods, etc., are ok) lurking around in the depths of the text.  You can do this by ennumerating all the text's unique characters, examining them, and then replacing any unwanted characters with empty spaces!  Once we find all of the text's unique characters, we can remove all of the atypical ones in the next cell.  Note: don't remove the punctuation marks given in my_answers.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: implement cleaned_text in my_answers.py\n",
    "from my_answers import cleaned_text\n",
    "\n",
    "text = cleaned_text(text)\n",
    "\n",
    "# shorten any extra dead space created above\n",
    "text = text.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your chosen characters removed print out the first few hundred lines again just to double check that everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer excellent for drawing the veil from men s motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene adler, of dubious and questionable memory. i had seen little of holmes lately. my marriage had drifted us away from each other. my own complete happiness, and the home centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while holmes, who loathed every form of society with his whole bohemian soul, remained in our lodgings in baker street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. he was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. from time to time i heard some vague account of his doings: of his summons to odessa in the case of the trepoff murder, of his clearing up o'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 2000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have thrown out a good number of non-English characters/character sequences lets print out some statistics about the dataset - including number of total characters and number of unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 573681 total number of characters\n",
      "this corpus has 33 unique characters\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# print some of the text, as well as statistics\n",
    "print (\"this corpus has \" +  str(len(text)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Cutting data into input/output pairs\n",
    "\n",
    "Now that we have our text all cleaned up, how can we use it to train a model to generate sentences automatically?  First we need to train a machine learning model - and in order to do that we need a set of input/output pairs for a model to train on.  How can we create a set of input/output pairs from our text to train on?\n",
    "\n",
    "Remember in part 1 of this notebook how we used a sliding window to extract input/output pairs from a time series?  We do the same thing here!  We slide a window of length $T$ along our giant text corpus - everything in the window becomes one input while the character following becomes its corresponding output.  This process of extracting input/output pairs is illustrated in the gif below on a small example text using a window size of T = 5.\n",
    "\n",
    "<img src=\"images/text_windowing_training.gif\" width=400 height=400/>\n",
    "\n",
    "Notice one aspect of the sliding window in this gif that does not mirror the analaogous gif for time series shown in part 1 of the notebook - we do not need to slide the window along one character at a time but can move by a fixed step size $M$ greater than 1 (in the gif indeed $M = 1$).  This is done with large input texts (like ours which has over 500,000 characters!) when sliding the window along one character at a time we would create far too many input/output pairs to be able to reasonably compute with.\n",
    "\n",
    "More formally lets denote our text corpus - which is one long string of characters - as follows\n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $P$ is the length of the text (again for our text $P \\approx 500,000!$).  Sliding a window of size T = 5 with a step length of M = 1 (these are the parameters shown in the gif above) over this sequence produces the following list of input/output pairs\n",
    "\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of 4 characters (and in general has length equal to the window size T) while each corresponding output is a single character.  We created around P total number of input/output pairs  (for general step size M we create around ceil(P/M) pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_4'></a>\n",
    "\n",
    "Now its time for you to window the input time series as described above! \n",
    "\n",
    "**TODO:** Create a function that runs a sliding window along the input text and creates associated input/output pairs.  A skeleton function has been provided for you.  Note that this function should input a) the text  b) the window size and c) the step size, and return the input/output sequences.  Note: the return items should be *lists* - not numpy arrays.\n",
    "\n",
    "(remember to copy your completed function into the script *my_answers.py* function titled *window_transform_text* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: implement window_transform_series in my_answers.py\n",
    "from my_answers import window_transform_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function complete we can now use it to produce input/output pairs!  We employ the function in the next cell, where the window_size = 100 and step_size = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your text window-ing function \n",
    "window_size = 100\n",
    "step_size = 5\n",
    "inputs, outputs = window_transform_text(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print out a few input/output pairs to verify that we have made the right sort of stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = e eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love f\n",
      "output = o\n",
      "--------------\n",
      "input = er excellent for drawing the veil from men s motives and actions. but for the trained reasoner to ad\n",
      "output = m\n"
     ]
    }
   ],
   "source": [
    "# print out a few of the input/output pairs to verify that we've made the right kind of stuff to learn from\n",
    "print('input = ' + inputs[2])\n",
    "print('output = ' + outputs[2])\n",
    "print('--------------')\n",
    "print('input = ' + inputs[100])\n",
    "print('output = ' + outputs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4  Wait, what kind of problem is text generation again?\n",
    "\n",
    "In part 1 of this notebook we used the same pre-processing technique - the sliding window - to produce a set of training input/output pairs to tackle the problem of time series prediction *by treating the problem as one of regression*.  So what sort of problem do we have here now, with text generation?  Well, the time series prediction was a regression problem because the output (one value of the time series) was a continuous value.  Here - for character-by-character text generation - each output is a *single character*.  This isn't a continuous value - but a distinct class - therefore **character-by-character text generation is a classification problem**.  \n",
    "\n",
    "How many classes are there in the data?  Well, the number of classes is equal to the number of unique characters we have to predict!  How many of those were there in our dataset again?  Lets print out the value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 33 unique characters\n",
      "and these characters are \n",
      "[' ', '!', ',', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique characters in the dataset\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"this corpus has \" +  str(len(chars)) + \" unique characters\")\n",
    "print('and these characters are ')\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rockin' - so we have a multi-class classification problem on our hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5  One-hot encoding characters\n",
    "\n",
    "There's just one last issue we have to deal with before tackle: machine learning algorithm deal with numerical data and all of our input/output pairs are characters.  So we just need to transform our characters into equivalent numerical values.  The most common way of doing this is via a 'one-hot encoding' scheme.  Here's how it works.\n",
    "\n",
    "We transform each character in our inputs/outputs into a vector with length equal to the number of unique characters in our text.  This vector is all zeros except one location where we place a 1 - and this location is unique to each character type.  e.g., we transform 'a', 'b', and 'c' as follows\n",
    "\n",
    "$$a\\longleftarrow\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,\\,\\,b\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,c\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0 \n",
    "\\end{array}\\right]\\cdots$$\n",
    "\n",
    "where each vector has 32 entries (or in general: number of entries = number of unique characters in text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first practical step towards doing this one-hot encoding is to form a dictionary mapping each unique character to a unique integer, and one dictionary to do the reverse mapping.  We can then use these dictionaries to quickly make our one-hot encodings, as well as re-translate (from integers to characters) the results of our trained RNN classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can transform our input/output pairs - consisting of characters - to equivalent input/output pairs made up of one-hot encoded vectors.  In the next cell we provide a function for doing just this: it takes in the raw character input/outputs and returns their numerical versions.  In particular the numerical input is given as $\\bf{X}$, and numerical output is given as the $\\bf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text, window_size, step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text, window_size, step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the one-hot encoding function by activating the cell below and transform our input/output pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your function\n",
    "window_size = 100\n",
    "step_size = 5\n",
    "X, y = encode_io_pairs(text, window_size, step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_5'></a>\n",
    "\n",
    "## 2.6 Setting up our RNN\n",
    "\n",
    "With our dataset loaded and the input/output pairs extracted / transformed we can now begin setting up our RNN for training.  Again we will use Keras to quickly build a single hidden layer RNN - where our hidden layer consists of LTSM modules.\n",
    "\n",
    "Time to get to work: build a 3 layer RNN model of the following specification\n",
    "\n",
    "- layer 1 should be an LSTM module with 200 hidden units --> note this should have input_shape = (window_size,len(chars)) where len(chars) = number of unique characters in your cleaned text\n",
    "- layer 2 should be a linear module, fully connected, with len(chars) hidden units --> where len(chars) = number of unique characters in your cleaned text\n",
    "- layer 3 should be a softmax activation ( since we are solving a *multiclass classification*)\n",
    "- Use the **categorical_crossentropy** loss \n",
    "\n",
    "This network can be constructed using just a few lines - as with the RNN network you made in part 1 of this notebook.  See e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LTSM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random\n",
    "\n",
    "# TODO implement build_part2_RNN in my_answers.py\n",
    "from my_answers import build_part2_RNN\n",
    "\n",
    "model = build_part2_RNN(window_size, len(chars))\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7  Training our RNN model for text generation\n",
    "\n",
    "With our RNN setup we can now train it!  Lets begin by trying it out on a small subset of the larger version.  In the next cell we take the first 10,000 input/output pairs from our training database to learn on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small subset of our input/output pairs\n",
    "Xsmall = X[:10000,:,:]\n",
    "ysmall = y[:10000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochtimer = EpochTimer()\n",
    "epochs = 40\n",
    "hist = model.fit(Xsmall, ysmall, batch_size=500, epochs=epochs, verbose=1, callbacks=[epochtimer])\n",
    "show_history_graph(hist)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_small_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we make a given number of predictions (characters) based on this fitted model?   \n",
    "\n",
    "First we predict the next character after following any chunk of characters in the text of length equal to our chosen window size.  Then we remove the first character in our input sequence and tack our prediction onto the end.  This gives us a slightly changed sequence of inputs that still has length equal to the size of our window.  We then feed in this updated input sequence into the model to predict the another character.  Together then we have two predicted characters following our original input sequence.  Repeating this process N times gives us N predicted characters.\n",
    "\n",
    "In the next Python cell we provide you with a completed function that does just this - it makes predictions when given a) a trained RNN model, b) a subset of (window_size) characters from the text, and c) a number of characters to predict (to follow our input subset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that uses trained model to predict a desired number of future characters\n",
    "def predict_next_chars(model,input_chars,num_to_predict):     \n",
    "    # create output\n",
    "    predicted_chars = ''\n",
    "    for i in range(num_to_predict):\n",
    "        # convert this round's predicted characters to numerical input    \n",
    "        x_test = np.zeros((1, window_size, len(chars)))\n",
    "        for t, char in enumerate(input_chars):\n",
    "            x_test[0, t, chars_to_indices[char]] = 1.\n",
    "\n",
    "        # make this round's prediction\n",
    "        test_predict = model.predict(x_test,verbose = 0)[0]\n",
    "\n",
    "        # translate numerical prediction back to characters\n",
    "        r = np.argmax(test_predict)                           # predict class of each test input\n",
    "        d = indices_to_chars[r] \n",
    "\n",
    "        # update predicted_chars and input\n",
    "        predicted_chars+=d\n",
    "        input_chars+=d\n",
    "        input_chars = input_chars[1:]\n",
    "    return predicted_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_6'></a>\n",
    "\n",
    "With your trained model try a few subsets of the complete text as input - note the length of each must be exactly equal to the window size.  For each subset us the function above to predict the next 100 characters that follow each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it\n",
    "# get an appropriately sized chunk of characters from the text\n",
    "start_inds = []\n",
    "\n",
    "# load in weights\n",
    "model.load_weights('model_weights/best_RNN_small_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    print('------------------')\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks ok, but not great.  Now lets try the same experiment with a larger chunk of the data - with the first 100,000 input/output pairs.  \n",
    "\n",
    "Tuning RNNs for a typical character dataset like the one we will use here is a computationally intensive endeavour and thus timely on a typical CPU.  Using a reasonably sized cloud-based GPU can speed up training by a factor of 10.  Also because of the long training time it is highly recommended that you carefully write the output of each step of your process to file.  This is so that all of your results are saved even if you close the web browser you're working out of, as the processes will continue processing in the background but variables/output in the notebook system will not update when you open it again.\n",
    "\n",
    "In the next cell we show you how to create a text file in Python and record data to it.  This sort of setup can be used to record your final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A simple way to write output to file\n",
    "f = open('my_test_output.txt', 'w')              # create an output file to write too\n",
    "f.write('this is only a test ' + '\\n')           # print some output text\n",
    "x = 2\n",
    "f.write('the value of x is ' + str(x) + '\\n')    # record a variable value\n",
    "f.close()     \n",
    "\n",
    "# print out the contents of my_test_output.txt\n",
    "f = open('my_test_output.txt', 'r')              # create an output file to write too\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this recording devices we can now more safely perform experiments on larger portions of the text.  In the next cell we will use the first 100,000 input/output pairs to train our RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we fit our model to the dataset, then generate text using the trained model in precisely the same generation method applied before on the small dataset.\n",
    "\n",
    "**Note:** your generated words should be - by and large - more realistic than with the small dataset, but you won't be able to generate perfect English sentences even with this amount of data.  A rule of thumb: your model is working well if you generate sentences that largely contain real English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small subset of our input/output pairs\n",
    "Xlarge = X[:100000,:,:]\n",
    "ylarge = y[:100000,:]\n",
    "\n",
    "# TODO: fit to our larger dataset\n",
    "model.fit(Xlarge, ylarge, batch_size=500, nb_epoch=30,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_large_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it\n",
    "# get an appropriately sized chunk of characters from the text\n",
    "start_inds = []\n",
    "\n",
    "# save output\n",
    "f = open('text_gen_output/RNN_large_textdata_output.txt', 'w')  # create an output file to write too\n",
    "\n",
    "# load weights\n",
    "model.load_weights('model_weights/best_RNN_large_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    line = '-------------------' + '\\n'\n",
    "    print(line)\n",
    "    f.write(line)\n",
    "\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "    f.write(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    predict_line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(predict_line)\n",
    "    f.write(predict_line)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
